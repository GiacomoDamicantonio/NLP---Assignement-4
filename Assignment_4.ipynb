{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di Assignment_4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GM9DBN-Qz3k"
      },
      "source": [
        "# Assignment 4\n",
        "\n",
        "**Due to**: TBD\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Fact checking, Neural Languange Inference (**NLI**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO_-4CZeRCO7"
      },
      "source": [
        "# Intro\n",
        "\n",
        "This assignment is centred on a particular and emerging NLP task, formally known as **fact checking** (or fake checking). As AI techniques become more and more powerful, reaching amazing results, such as image and text generation, it is more than ever necessary to build tools able to distinguish what is real from what is fake.\n",
        "\n",
        "Here we focus on a small portion of the whole fact checking problem, which aims to determine whether a given statement (fact) conveys a trustworthy information or not. \n",
        "\n",
        "More precisely, given a set of evidences and a fact to verify, we would like our model to correctly predict whether the fact is true or fake.\n",
        "\n",
        "In particular, we will see:\n",
        "\n",
        "*   Dataset preparation (analysis and pre-processing)\n",
        "*   Problem formulation: multi-input binary classification\n",
        "*   Defining an evaluation method\n",
        "*   Simple sentence embedding\n",
        "*   Neural building blocks\n",
        "*   Neural architecture extension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGDwg78PS_uy"
      },
      "source": [
        "# The FEVER dataset\n",
        "\n",
        "First of all, we need to choose a dataset. In this assignment we will rely on the [FEVER dataset](https://fever.ai).\n",
        "\n",
        "The dataset is about facts taken from Wikipedia documents that have to be verified. In particular, facts could face manual modifications in order to define fake information or to give different formulations of the same concept.\n",
        "\n",
        "The dataset consists of 185,445 claims manually verified against the introductory sections of Wikipedia pages and classified as ```Supported```, ```Refuted``` or ```NotEnoughInfo```. For the first two classes, systems and annotators need to also return the combination of sentences forming the necessary evidence supporting or refuting the claim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oa5FpVpT7p4"
      },
      "source": [
        "## Dataset structure\n",
        "\n",
        "Relevant data is divided into two file types. Information concerning the fact to verify, its verdict and associated supporting/opposing statements are stored in **.jsonl** format. In particular, each JSON element is a python dictionary with the following relevant fields:\n",
        "\n",
        "*    **ID**: ID associated to the fact to verify.\n",
        "\n",
        "*    **Verifiable**: whether the fact has been verified or not: ```VERIFIABLE``` or ```NOT VERIFIABLE```.\n",
        "    \n",
        "*    **Label**: the final verdict on the fact to verify: ```SUPPORTS```, ```REFUTES``` or ```NOT ENOUGH INFO```.\n",
        "    \n",
        "*    **Claim**: the fact to verify.\n",
        "    \n",
        "*    **Evidence**: a nested list of document IDs along with the sentence ID that is associated to the fact to verify. In particular, each list element is a tuple of four elements: the first two are internal annotator IDs that can be safely ignored; the third term is the document ID (called URL) and the last one is the sentence number (ID) in the pointed document to consider.\n",
        "\n",
        "**Some Examples**\n",
        "\n",
        "---\n",
        "\n",
        "**Verifiable**\n",
        "\n",
        "{\"id\": 202314, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"The New Jersey Turnpike has zero shoulders.\", \"evidence\": [[[238335, 240393, \"New_Jersey_Turnpike\", 15]]]}\n",
        "\n",
        "---\n",
        "\n",
        "**Not Verifiable**\n",
        "\n",
        "{\"id\": 113501, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Grease had bad reviews.\", \"evidence\": [[[133128, null, null, null]]]}\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nex_8UM4VWuY"
      },
      "source": [
        "## Some simplifications and pre-processing\n",
        "\n",
        "We are only interested in verifiable facts. Thus, we can filter out all non-verifiable claims.\n",
        "\n",
        "Additionally, the current dataset format does not contain all necessary information for our classification purposes. In particular, we need to download Wikipedia documents and replace reported evidence IDs with the corresponding text.\n",
        "\n",
        "Don't worry about that! We are providing you the already pre-processed dataset so that you can concentrate on the classification pipeline (pre-processing, model definition, evaluation and training).\n",
        "\n",
        "You can download the zip file containing all set splits (train, validation and test) of the FEVER dataset by clicking on this [link](https://drive.google.com/file/d/1wArZhF9_SHW17WKNGeLmX-QTYw9Zscl1/view?usp=sharing). Alternatively, run the below code cell to automatically download it on this notebook.\n",
        "\n",
        "**Note**: each dataset split is in .csv format. Feel free to inspect the whole dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BspxZcRjW0NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442ea7b5-5a53-473d-a4d4-4ce1186322b9"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(data_path):\n",
        "    toy_data_path = os.path.join(data_path, 'fever_data.zip')\n",
        "    toy_data_url_id = \"1wArZhF9_SHW17WKNGeLmX-QTYw9Zscl1\"\n",
        "    toy_url = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "\n",
        "    if not os.path.exists(toy_data_path):\n",
        "        print(\"Downloading FEVER data splits...\")\n",
        "        with requests.Session() as current_session:\n",
        "            response = current_session.get(toy_url,\n",
        "                                   params={'id': toy_data_url_id},\n",
        "                                   stream=True)\n",
        "        save_response_content(response, toy_data_path)\n",
        "        print(\"Download completed!\")\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(toy_data_path) as loaded_zip:\n",
        "            loaded_zip.extractall(data_path)\n",
        "        print(\"Extraction completed!\")\n",
        "\n",
        "download_data('dataset')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading FEVER data splits...\n",
            "Download completed!\n",
            "Extracting dataset...\n",
            "Extraction completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbH_8errW5MH"
      },
      "source": [
        "# Classification dataset\n",
        "\n",
        "At this point, you should have a reay-to-go dataset! Note that the dataset format changed as well! In particular, we split the evidence set associated to each claim, in order to build (claim, evidence) pairs. The classification label is propagated as well.\n",
        "\n",
        "We'll motivate this decision in the next section!\n",
        "\n",
        "Just for clarity, here's an example of the pre-processed dataset:\n",
        "\n",
        "---\n",
        "\n",
        "**Claim**: \"Wentworth Miller is yet to make his screenwriting debut.\"\n",
        "\n",
        "**Evidence**: \"2\tHe made his screenwriting debut with the 2013 thriller film Stoker .\tStoker\tStoker (film)\"\n",
        "\n",
        "**Label**: Refutes\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: The dataset requires some text cleaning as you may notice!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH8hIK21Xrl0"
      },
      "source": [
        "# Problem formulation\n",
        "\n",
        "As mentioned at the beginning of the assignment, we are going to formulate the fact checking problem as a binary classification task.\n",
        "\n",
        "In particular, each dataset sample is comprised of:\n",
        "\n",
        "*     A claim to verify\n",
        "*     A set of semantically related statements (evidence set)\n",
        "*     Fact checking label: either evidences support or refute the claim.\n",
        "\n",
        "Handling the evidence set from the point of view of neural models may imply some additional complexity: if the evidence set is comprised of several sentences we might incur in memory problems.\n",
        "\n",
        "To this end, we further simplify the problem by building (claim, evidence) pairs. The fact checking label is propagated as well.\n",
        "\n",
        "Example:\n",
        "\n",
        "     Claim: c1 \n",
        "     Evidence set: [e1, e2, e3]\n",
        "     Label: S (support)\n",
        "\n",
        "--->\n",
        "\n",
        "    (c1, e1, S),\n",
        "    (c1, e2, S),\n",
        "    (c1, e3, S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E46flIz_zQy-"
      },
      "source": [
        "## Schema\n",
        "\n",
        "The overall binary classification problem is summed up by the following (simplified) schema\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Wm_YBnFwgJtxcWEBpPbTBEVkpKaL08Jp)\n",
        "\n",
        "Don't worry too much about the **Encoding** block for now. We'll give you some simple guidelines about its definition. For the moment, stick to the binary classification task definition where, in this case, we have 2 inputs: the claim to verify and one of its associated evidences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsiTV-NVdgsF"
      },
      "source": [
        "# Architecture Guidelines\n",
        "\n",
        "There are many neural architectures that follow the above schema. To avoid phenomena like the writer's block, in this section we are going to give you some implementation guidelines.\n",
        "\n",
        "In particular, we would like you to test some implementations so that you explore basic approaches (neural baselines) and use them as building blocks for possible extensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJBQm47fe7iE"
      },
      "source": [
        "## Handling multiple inputs\n",
        "\n",
        "The first thing to notice is that we are in a multi-input scenario. In particular, each sample is comprised of a fact and its asssociated evidence statement.\n",
        "\n",
        "Each of these input is encoded as a sequence of tokens. In particular, we will have the following input matrices:\n",
        "\n",
        "*    Claim: [batch_size, max_tokens]\n",
        "*    Evidence: [batch_size, max_tokens]\n",
        "\n",
        "Moreover, after the embedding layer, we'll have:\n",
        "\n",
        "*    Claim: [batch_size, max_tokens, embedding_dim]\n",
        "*    Evidence: [batch_size, max_tokens, embedding_dim]\n",
        "\n",
        "But, we would like to have a 2D input to our classifier, since we have to give an answer at pair level. Therefore, for each sample, we would expect the following input shape to our classification block:\n",
        "\n",
        "*   Classification input shape: [batch_size, dim]\n",
        "\n",
        "**How to do that?**\n",
        "\n",
        "We inherently need to reduce the token sequence to a single representation. This operation is formally known as **sentence embedding**. Indeed, we are trying to compress the information of a whole sequence into a single embedding vector.\n",
        "\n",
        "Here are some simple solutions that we ask you to try out:\n",
        "\n",
        "*   Encode token sequences via a RNN and take the last state as the sentence embedding.\n",
        "\n",
        "*   Encode token sequences via a RNN and average all the output states.\n",
        "\n",
        "*   Encode token sequences via a simple MLP layer. In particular, if your input is a [batch_size, max_tokens, embedding_dim] tensor, the matrix multiplication works on the **max_tokens** dimension, resulting in a [batch_size, embedding_dim] 2D matrix.\n",
        "\n",
        "*   Compute the sentence embedding as the mean of its token embeddings (**bag of vectors**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gypl5z5ElJo1"
      },
      "source": [
        "## Merging multi-inputs\n",
        "\n",
        "At this point, we have to think about **how** we should merge evidence and claim sentence embeddings.\n",
        "\n",
        "For simplicity, we stick to simple merging strategies:\n",
        "\n",
        "*     **Concatenation**: define the classification input as the concatenation of evidence and claim sentence embeddings\n",
        "\n",
        "*     **Sum**: define the classification input as the sum of evidence and claim sentence embeddings\n",
        "\n",
        "*     **Mean**: define the classification input as the mean of evidence and claim sentence embeddings\n",
        "\n",
        "For clarity, if we the sentence embedding of a single input has shape [batch_size, embedding_dim], then the classification input has shape:\n",
        "\n",
        "*     **Concatenation**: [batch_size, 2 * embedding_dim]\n",
        "\n",
        "*     **Sum**: [batch_size, embedding_dim]\n",
        "\n",
        "*     **Mean**: [batch_size, embedding_dim]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhVg9ZLymOUc"
      },
      "source": [
        "# A simple extension\n",
        "\n",
        "Lastly, we ask you to modify previously defined neural architectures by adding an additional feature to the classification input.\n",
        "\n",
        "We would like to see if some similarity information between the claim to verify and one of its associated evidence might be useful to the classification.\n",
        "\n",
        "Compute the cosine similarity metric between the two sentence embeddings and concatenate the result to the classification input.\n",
        "\n",
        "For clarity, since the cosine similarity of two vectors outputs a scalar value, the classification input shape is modified as follows:\n",
        "\n",
        "*     **Concatenation**: [batch_size, 2 * embedding_dim + 1]\n",
        "\n",
        "*     **Sum**: [batch_size, embedding_dim + 1]\n",
        "\n",
        "*     **Mean**: [batch_size, embedding_dim + 1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd74ULgpnJrc"
      },
      "source": [
        "# Performance evaluation\n",
        "\n",
        "Due to our simplifications, obtained results are not directly compatible with a traditional fact checking method that considers the evidence set as a whole.\n",
        "\n",
        "Thus, we need to consider two types of evaluations.\n",
        "\n",
        "**Multi-input classification evaluation**\n",
        "\n",
        "This type of evaluation is the easiest and concerns computing evaluation metrics, such as accuracy, f1-score, recall and precision, of our pre-processed dataset.\n",
        "\n",
        "In other words, we assess the performance of chosen classifiers.\n",
        "\n",
        "**Claim verification evaluation**\n",
        "\n",
        "However, if we want to give an answer concerning the claim itself, we need to consider the whole evidence set. \n",
        "\n",
        "Intuitively, for a given claim, we consider all its corresponding (claim, evidence) pairs and their corresponding classification outputs. \n",
        "\n",
        "At this point, all we need to do is to compute the final predicted claim label via majority voting.\n",
        "\n",
        "Example:\n",
        "\n",
        "    Claim: c1\n",
        "    Evidence set: e1, e2, e3\n",
        "    True label: S\n",
        "\n",
        "    Pair outputs:\n",
        "    (c1, e1) -> S (supports)\n",
        "    (c1, e2) -> S (supports)\n",
        "    (c1, e3) -> R (refutes)\n",
        "\n",
        "    Majority voting:\n",
        "    S -> 2 votes\n",
        "    R -> 1 vote\n",
        "\n",
        "    Final label:\n",
        "    c1 -> S\n",
        "\n",
        "Lastly, we have to compute classification metrics just like before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4LJ2yPxsUOV"
      },
      "source": [
        "# Tips and Extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf80UVRNrXve"
      },
      "source": [
        "## Extensions are welcome!\n",
        "\n",
        "Is this task too easy for you? Are you curious to try out things you have seen during lectures (e.g. attention)? Feel free to try everything you want!\n",
        "\n",
        "Don't forget to try neural baselines first!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXeCXdYsBEf"
      },
      "source": [
        "## Comments and documentation\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejv6SDE8xc4_"
      },
      "source": [
        "## Organization\n",
        "\n",
        "We suggest you to divide your work into sections. This allows you to build clean and modular code, as well as easy to read and to debug.\n",
        "\n",
        "A possible schema:\n",
        "\n",
        "*   Dataset pre-processing\n",
        "*   Dataset conversion\n",
        "*   Model definition\n",
        "*   Training\n",
        "*   Evaluation\n",
        "*   Comments/Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DR70uh7pabo"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it\n",
        "\n",
        "Don't forget that your feedback is very important! Your suggestions help us improving course material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc0gNWU2pgKQ"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "---\n",
        "\n",
        "**Q: Can I do something text pre-processing?**\n",
        "\n",
        "**A:** You have to! If you check text data, the majority of sentences need some cleaning.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: I'm struggling with the implementation. Can you help me?**\n",
        "\n",
        "**A:** Yes sure! Write us an email about your issue. If you are looking for a particular type of operation, you can easily check the documentation of the deep learning framework you are using (google is your friend).\n",
        "\n",
        "---\n",
        "\n",
        "**Q: Can I try other encoding strategies or neural architectures?**\n",
        "\n",
        "**A:** Absolutely! Remember to try out recommended neural baselines first and only then proceed with your extensions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giikfC36CybU"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "ym7EfuE7Cz1e",
        "outputId": "23967163-70f0-4c43-9ed0-14c80bf4e94a"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "train = pd.read_csv('./dataset/train_pairs.csv')\n",
        "test = pd.read_csv('./dataset/test_pairs.csv')\n",
        "val = pd.read_csv('./dataset/val_pairs.csv')\n",
        "train"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Claim</th>\n",
              "      <th>Evidence</th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Chris Hemsworth appeared in A Perfect Getaway.</td>\n",
              "      <td>2\\tHemsworth has also appeared in the science ...</td>\n",
              "      <td>3</td>\n",
              "      <td>SUPPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Roald Dahl is a writer.</td>\n",
              "      <td>0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...</td>\n",
              "      <td>7</td>\n",
              "      <td>SUPPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Roald Dahl is a governor.</td>\n",
              "      <td>0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...</td>\n",
              "      <td>8</td>\n",
              "      <td>REFUTES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ireland has relatively low-lying mountains.</td>\n",
              "      <td>10\\tThe island 's geography comprises relative...</td>\n",
              "      <td>9</td>\n",
              "      <td>SUPPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Ireland does not have relatively low-lying mou...</td>\n",
              "      <td>10\\tThe island 's geography comprises relative...</td>\n",
              "      <td>10</td>\n",
              "      <td>REFUTES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121735</th>\n",
              "      <td>121735</td>\n",
              "      <td>April was the month Anderson Silva was born.</td>\n",
              "      <td>0\\tAnderson da Silva -LRB- -LSB- ˈɐ̃deʁsõ ˈsiw...</td>\n",
              "      <td>229440</td>\n",
              "      <td>SUPPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121736</th>\n",
              "      <td>121736</td>\n",
              "      <td>Anderson Silva is an American Brazilian mixed ...</td>\n",
              "      <td>0\\tAnderson da Silva -LRB- -LSB- ˈɐ̃deʁsõ ˈsiw...</td>\n",
              "      <td>229443</td>\n",
              "      <td>REFUTES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121737</th>\n",
              "      <td>121737</td>\n",
              "      <td>Anderson Silva is incapable of being a Brazili...</td>\n",
              "      <td>0\\tAnderson da Silva -LRB- -LSB- ˈɐ̃deʁsõ ˈsiw...</td>\n",
              "      <td>229444</td>\n",
              "      <td>REFUTES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121738</th>\n",
              "      <td>121738</td>\n",
              "      <td>Anderson Silva was born on the month of April ...</td>\n",
              "      <td>0\\tAnderson da Silva -LRB- -LSB- ˈɐ̃deʁsõ ˈsiw...</td>\n",
              "      <td>229445</td>\n",
              "      <td>SUPPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121739</th>\n",
              "      <td>121739</td>\n",
              "      <td>Anderson Silva was born on the day of the 15th.</td>\n",
              "      <td>0\\tAnderson da Silva -LRB- -LSB- ˈɐ̃deʁsõ ˈsiw...</td>\n",
              "      <td>229448</td>\n",
              "      <td>REFUTES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121740 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...     Label\n",
              "0                0  ...  SUPPORTS\n",
              "1                1  ...  SUPPORTS\n",
              "2                2  ...   REFUTES\n",
              "3                3  ...  SUPPORTS\n",
              "4                4  ...   REFUTES\n",
              "...            ...  ...       ...\n",
              "121735      121735  ...  SUPPORTS\n",
              "121736      121736  ...   REFUTES\n",
              "121737      121737  ...   REFUTES\n",
              "121738      121738  ...  SUPPORTS\n",
              "121739      121739  ...   REFUTES\n",
              "\n",
              "[121740 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_b9dMbTOpc2",
        "outputId": "b9f11bdb-4cac-4487-e7e3-782342f8c193"
      },
      "source": [
        "ls = []\n",
        "\n",
        "def combine_words(input, length):\n",
        "    combined_inputs = []\n",
        "    if len(input)>1:\n",
        "        for i in range(len(input)-1):\n",
        "            combined_inputs.append(input[i]+\" \"+last_word_of(input[i+1],length)) #add the last word of the right-neighbour (overlapping) sequence (before it has expanded), which is the next word in the original sentence\n",
        "    return combined_inputs, length+1\n",
        "\n",
        "def remove_duplicates(input, length):\n",
        "    bool_broke=False #this means we didn't find any duplicates here\n",
        "    for i in range(len(input) - length):\n",
        "        if input[i]==input[i + length]: #found a duplicate piece of sentence!\n",
        "            for j in range(0,length): #remove the overlapping sequences in reverse order\n",
        "                del input[i + length - j]\n",
        "            bool_broke = True\n",
        "            break #break the for loop as the loop length does not matches the length of splitted_input anymore as we removed elements\n",
        "    if bool_broke:\n",
        "        return remove_duplicates(input, length) #if we found a duplicate, look for another duplicate of the same length\n",
        "    return input\n",
        "\n",
        "def last_word_of(input, length):\n",
        "    splitted = input.split(\" \")\n",
        "    if len(splitted)==0:\n",
        "        return input\n",
        "    else:\n",
        "        return splitted[length-1]\n",
        "\n",
        "def prepare_evidence(df):\n",
        "  ls = []\n",
        "  index = 0\n",
        "  for x in df['Evidence']:\n",
        "    i = re.sub(r'^.*?\\t', '', x)\n",
        "    splitted_input = i.replace('-LRB-', '(').replace('-RRB- ', ')').replace('\\t', ' ').replace('-LSB-', '').replace('-RSB-', '').split(' ')\n",
        "    word_length = 1\n",
        "    splitted_input,word_length = combine_words(splitted_input,word_length)\n",
        "\n",
        "    intermediate_output = False\n",
        "\n",
        "    while len(splitted_input)>1:\n",
        "        splitted_input = remove_duplicates(splitted_input,word_length) #look whether two sequences of length n (with distance n apart) are equal. If so, remove the n overlapping sequences\n",
        "        splitted_input, word_length = combine_words(splitted_input,word_length) #make even bigger sequences\n",
        "        if intermediate_output:\n",
        "            print(splitted_input)\n",
        "            print(word_length)\n",
        "    try:\n",
        "      output = splitted_input[0]\n",
        "    except:\n",
        "      output = splitted_input\n",
        "    index += 1\n",
        "    ls.append(output)\n",
        "  return(ls)\n",
        "\n",
        "train_evidence = prepare_evidence(train)\n",
        "test_evidence = prepare_evidence(test)\n",
        "val_evidence = prepare_evidence(val)\n",
        "print(train_evidence[0], test_evidence[0], val_evidence[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hemsworth has also appeared in the science fiction action film Star Trek ( 2009 ), the thriller adventure A Perfect Getaway ( 2009 ), the horror comedy The Cabin in the Woods ( 2012 ), the dark-fantasy action film Snow White and the Huntsman ( 2012 ), the war film Red Dawn ( 2012 ), and the biographical sports drama film Rush ( 2013 ). Star Trek (film) A Perfect Getaway The Cabin in the Woods Snow White and the Huntsman Red Dawn (2012 film) Rush Rush (2013 film) Furthermore , anxiety has been linked with physical symptoms such as IBS and can heighten other mental health illnesses such as OCD and panic disorder . IBS Irritable bowel syndrome It is an all-volunteer force and comprises more than 80 % of the country 's active defence personnel . all-volunteer force Volunteer military\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoilgL6nOpsq",
        "outputId": "f597be8b-9d38-479c-d5af-6602800277cf"
      },
      "source": [
        "X_train = [(train.iloc[x]['Claim'], train_evidence[x]) for x in range(len(train_evidence))]\n",
        "X_test = [(test.iloc[x]['Claim'], test_evidence[x]) for x in range(len(test_evidence))]\n",
        "X_val = [(val.iloc[x]['Claim'], val_evidence[x]) for x in range(len(val_evidence))]\n",
        "X_train[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Chris Hemsworth appeared in A Perfect Getaway.',\n",
              " 'Hemsworth has also appeared in the science fiction action film Star Trek ( 2009 ), the thriller adventure A Perfect Getaway ( 2009 ), the horror comedy The Cabin in the Woods ( 2012 ), the dark-fantasy action film Snow White and the Huntsman ( 2012 ), the war film Red Dawn ( 2012 ), and the biographical sports drama film Rush ( 2013 ). Star Trek (film) A Perfect Getaway The Cabin in the Woods Snow White and the Huntsman Red Dawn (2012 film) Rush Rush (2013 film)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3oYBL2SLG3m"
      },
      "source": [
        "y_train = train['Label']\n",
        "y_test = test['Label']\n",
        "y_val = val['Label']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cLxaKZrC04V"
      },
      "source": [
        "# CONVERSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pye_KlG5yGl"
      },
      "source": [
        "pos_dict = {}\n",
        "def create_XY(df):\n",
        "    X = [] # store input sequence\n",
        "    pos = 0\n",
        "    max_len = 0\n",
        "    for sentence in df:\n",
        "      X_sentence = []\n",
        "      try:\n",
        "        sent = sentence.split(' ')\n",
        "        for word in sent:\n",
        "          if len(sent) > max_len:\n",
        "            max_len = len(sent)\n",
        "          X_sentence.append(word)\n",
        "      except:\n",
        "          X_sentence.append('')\n",
        "      X.append(X_sentence)\n",
        "    num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "    print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "    print(\"Vocabulary size: {}\".format(num_words))\n",
        "    print('sample X: ', X[0])\n",
        "    print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
        "    print(\"Maximum length of sentence : {} \\n\".format(max_len))\n",
        "    return X, num_words, max_len\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRCkzdb2H3Wr",
        "outputId": "0b4029d4-9597-4bcb-db12-42ec7b13ab9d"
      },
      "source": [
        "X_train_claim, num_words_train_claim, MAX_LEN_TRAIN_claim = create_XY(train['Claim'])\n",
        "X_val_claim, num_words_val_claim, MAX_LEN_VAL_claim = create_XY(val['Claim'])\n",
        "X_test_claim, num_words_test_claim, MAX_LEN_TEST_claim= create_XY(test['Claim'])\n",
        "\n",
        "X_train_evidence, num_words_train_evidence, MAX_LEN_TRAIN_evidence = create_XY(train_evidence)\n",
        "X_val_evidence, num_words_val_evidence, MAX_LEN_VAL_evidence = create_XY(val_evidence)\n",
        "X_test_evidence, num_words_test_evidence, MAX_LEN_TEST_evidence = create_XY(test_evidence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tagged sentences: 121740\n",
            "Vocabulary size: 31186\n",
            "sample X:  ['Chris', 'Hemsworth', 'appeared', 'in', 'A', 'Perfect', 'Getaway.']\n",
            "Length of first input sequence  : 7\n",
            "Maximum length of sentence : 65 \n",
            "\n",
            "Total number of tagged sentences: 7165\n",
            "Vocabulary size: 6619\n",
            "sample X:  ['The', 'Indian', 'Army', 'comprises', 'part', 'of', 'the', \"country's\", 'active', 'defense', 'personnel.']\n",
            "Length of first input sequence  : 11\n",
            "Maximum length of sentence : 31 \n",
            "\n",
            "Total number of tagged sentences: 7189\n",
            "Vocabulary size: 7141\n",
            "sample X:  ['Anxiety', 'has', 'been', 'linked', 'with', 'physical', 'symptoms.']\n",
            "Length of first input sequence  : 7\n",
            "Maximum length of sentence : 31 \n",
            "\n",
            "Total number of tagged sentences: 121740\n",
            "Vocabulary size: 36238\n",
            "sample X:  ['Hemsworth', 'has', 'also', 'appeared', 'in', 'the', 'science', 'fiction', 'action', 'film', 'Star', 'Trek', '(', '2009', '),', 'the', 'thriller', 'adventure', 'A', 'Perfect', 'Getaway', '(', '2009', '),', 'the', 'horror', 'comedy', 'The', 'Cabin', 'in', 'the', 'Woods', '(', '2012', '),', 'the', 'dark-fantasy', 'action', 'film', 'Snow', 'White', 'and', 'the', 'Huntsman', '(', '2012', '),', 'the', 'war', 'film', 'Red', 'Dawn', '(', '2012', '),', 'and', 'the', 'biographical', 'sports', 'drama', 'film', 'Rush', '(', '2013', ').', 'Star', 'Trek', '(film)', 'A', 'Perfect', 'Getaway', 'The', 'Cabin', 'in', 'the', 'Woods', 'Snow', 'White', 'and', 'the', 'Huntsman', 'Red', 'Dawn', '(2012', 'film)', 'Rush', 'Rush', '(2013', 'film)']\n",
            "Length of first input sequence  : 89\n",
            "Maximum length of sentence : 203 \n",
            "\n",
            "Total number of tagged sentences: 7165\n",
            "Vocabulary size: 8586\n",
            "sample X:  ['It', 'is', 'an', 'all-volunteer', 'force', 'and', 'comprises', 'more', 'than', '80', '%', 'of', 'the', 'country', \"'s\", 'active', 'defence', 'personnel', '.', 'all-volunteer', 'force', 'Volunteer', 'military']\n",
            "Length of first input sequence  : 23\n",
            "Maximum length of sentence : 168 \n",
            "\n",
            "Total number of tagged sentences: 7189\n",
            "Vocabulary size: 9723\n",
            "sample X:  ['Furthermore', ',', 'anxiety', 'has', 'been', 'linked', 'with', 'physical', 'symptoms', 'such', 'as', 'IBS', 'and', 'can', 'heighten', 'other', 'mental', 'health', 'illnesses', 'such', 'as', 'OCD', 'and', 'panic', 'disorder', '.', 'IBS', 'Irritable', 'bowel', 'syndrome']\n",
            "Length of first input sequence  : 30\n",
            "Maximum length of sentence : 152 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zydzkpXhVL1B"
      },
      "source": [
        "words, tags = set([]), set([])\n",
        "X_train = X_train_claim + X_train_evidence\n",
        " \n",
        "for s in X_train:\n",
        "    for w in s:\n",
        "       words.add(w.lower())\n",
        " \n",
        "word2index = {w: i + 1 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBFuGCU4DMXA"
      },
      "source": [
        "words_test, tags_test = set([]), set([])\n",
        "X_test = X_test_claim + X_test_evidence\n",
        "\n",
        "for s in X_test:\n",
        "    for w in s:\n",
        "       words_test.add(w.lower())\n",
        " \n",
        "word2indexTest = {w: i + 2 for i, w in enumerate(list(words_test))}\n",
        "word2indexTest['-PAD-'] = 0  # The special value used for padding"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Vh9gJfgpB-"
      },
      "source": [
        "words_val, tags_val = set([]), set([])\n",
        "X_val = X_val_claim + X_val_evidence\n",
        "\n",
        "for s in X_val:\n",
        "    for w in s:\n",
        "       words_val.add(w.lower())\n",
        " \n",
        "word2indexVal = {w: i + 2 for i, w in enumerate(list(words_val))}\n",
        "word2indexVal['-PAD-'] = 0  # The special value used for padding"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBx_hrNhwGPo"
      },
      "source": [
        "## Merging indexes and padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku4yfV3rg3Tp"
      },
      "source": [
        "\n",
        "def merge_word2indexes(word2index, word2indexTest, word2indexVal): \n",
        "  for x in word2indexVal:\n",
        "    if x not in word2index.keys():\n",
        "      word2index[x] = len(word2index) \n",
        "  for x in word2indexTest:\n",
        "    if x not in word2index.keys():\n",
        "      word2index[x] = len(word2index) \n",
        "  return word2index\n",
        "word2index = merge_word2indexes(word2index, word2indexTest, word2indexVal)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZpNRGhqWMLf",
        "outputId": "0a5f02e2-37e2-43e6-97b9-530d10193c34"
      },
      "source": [
        "train_sentences_X_claim, test_sentences_X_claim, val_sentences_X_claim = [], [], []\n",
        "train_sentences_X_evidence, test_sentences_X_evidence, val_sentences_X_evidence = [], [], []\n",
        "\n",
        "oov = [] \n",
        "\n",
        "for s in X_train_claim:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        s_int.append(word2index[w.lower()])\n",
        "    train_sentences_X_claim.append(s_int)\n",
        "\n",
        "for s in X_train_evidence:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        s_int.append(word2index[w.lower()])\n",
        "    train_sentences_X_evidence.append(s_int)\n",
        "\n",
        "for s in X_test_claim:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        s_int.append(word2index[w.lower()])\n",
        "    test_sentences_X_claim.append(s_int)\n",
        "\n",
        "for s in X_test_evidence:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        s_int.append(word2index[w.lower()])\n",
        "    test_sentences_X_evidence.append(s_int)\n",
        "\n",
        "for s in X_val_claim:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        s_int.append(word2index[w.lower()])\n",
        "    val_sentences_X_claim.append(s_int)\n",
        "\n",
        "for s in X_val_evidence:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        s_int.append(word2index[w.lower()])\n",
        "    val_sentences_X_evidence.append(s_int)\n",
        " \n",
        "print(train_sentences_X_claim[0])\n",
        "print(test_sentences_X_claim[0])\n",
        "print(val_sentences_X_claim[0])\n",
        "print(train_sentences_X_evidence[0])\n",
        "print(test_sentences_X_evidence[0])\n",
        "print(val_sentences_X_evidence[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1644, 42899, 3630, 25313, 23059, 43034, 43583]\n",
            "[51953, 28908, 5591, 31637, 32844, 46992, 51780]\n",
            "[30729, 25343, 38580, 5438, 5433, 7676, 30729, 24613, 14604, 23157, 54573]\n",
            "[42899, 28908, 5359, 3630, 25313, 30729, 37500, 43214, 31813, 38373, 6256, 25057, 18440, 11051, 7683, 30729, 16063, 43424, 23059, 43034, 48459, 18440, 11051, 7683, 30729, 159, 4869, 30729, 24122, 25313, 30729, 24749, 18440, 13050, 7683, 30729, 19649, 31813, 38373, 8017, 48921, 3448, 30729, 49982, 18440, 13050, 7683, 30729, 14350, 38373, 40612, 37529, 18440, 13050, 7683, 3448, 30729, 37631, 4251, 22432, 38373, 31387, 18440, 17995, 19600, 6256, 25057, 11382, 23059, 43034, 48459, 30729, 24122, 25313, 30729, 24749, 8017, 48921, 3448, 30729, 49982, 40612, 37529, 30954, 19584, 31387, 31387, 23228, 19584]\n",
            "[44494, 2268, 51953, 28908, 5591, 31637, 32844, 46992, 25396, 11139, 3029, 56877, 3448, 23190, 57405, 35995, 14424, 43191, 12238, 11139, 3029, 57670, 3448, 45668, 22380, 33236, 56877, 57623, 28888, 30582]\n",
            "[34923, 35745, 29686, 53219, 17790, 3448, 5438, 28945, 40416, 35981, 45008, 7676, 30729, 8241, 46509, 14604, 9038, 20945, 33236, 53219, 17790, 35628, 35674]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv6JSvKIWzPf"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN_claim = 65\n",
        "MAX_LEN_evidence = 203\n",
        "\n",
        "train_sentences_X_claim = pad_sequences(train_sentences_X_claim, maxlen=MAX_LEN_claim, padding='post', truncating='post')\n",
        "val_sentences_X_claim = pad_sequences(val_sentences_X_claim, maxlen=MAX_LEN_claim, padding='post', truncating='post')\n",
        "test_sentences_X_claim = pad_sequences(test_sentences_X_claim, maxlen=MAX_LEN_claim, padding='post', truncating='post')\n",
        "\n",
        "train_sentences_X_evidence = pad_sequences(train_sentences_X_evidence, maxlen=MAX_LEN_evidence, padding='post', truncating='post')\n",
        "val_sentences_X_evidence = pad_sequences(val_sentences_X_evidence, maxlen=MAX_LEN_evidence, padding='post', truncating='post')\n",
        "test_sentences_X_evidence = pad_sequences(test_sentences_X_evidence, maxlen=MAX_LEN_evidence, padding='post', truncating='post')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quidmmGkC38D"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXR5lyC_C5Xs"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Add, Average, Dense, Input, GlobalMaxPooling1D, Dot, LSTM, Bidirectional, \\\n",
        "Dropout, Embedding, concatenate, Concatenate, GlobalAveragePooling1D, AdditiveAttention\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWmU94DCwZJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cf0e86-e777-412b-c29a-3176472f8c60"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 25.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 25.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 18.8MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 15.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 17.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 15.9MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=06dd92d5b733e25149330e9643876d0cb875a8f044853caa3ec785e1f0e722b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzJfAAnFwb7y"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import json\r\n",
        "import string\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\r\n",
        "VOCAB_SIZE = len(word2index)\r\n",
        "BATCH_SIZE = 128\r\n",
        "UNITS = 1024\r\n",
        "# default parameters and configuration for BERT Embedding\r\n",
        "configuration = BertConfig()  \r\n",
        "configuration.vocab_size = VOCAB_SIZE\r\n",
        "configuration.hidden_size = 256\r\n",
        "configuration.intermediate_size = 256\r\n",
        "configuration.num_attention_heads = 1\r\n",
        "configuration.num_hidden_layers = 1\r\n",
        "configuration.max_position_embeddings = MAX_LEN_TRAIN_evidence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YFgsOtmCpMc"
      },
      "source": [
        "claim_input = Input(shape=(MAX_LEN_TRAIN_claim), name='claim_input', dtype=tf.int32)\n",
        "evidence_input = Input(shape=(MAX_LEN_TRAIN_evidence), name='evidence_input', dtype=tf.int32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KAyf76Yhly0"
      },
      "source": [
        "## Reduce the token sequence to a single representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmJAEREWa9v"
      },
      "source": [
        "### RNN taking last hidden state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CDJQoRHDFhy"
      },
      "source": [
        "def last_state_model():  \n",
        "  claim_outputs1, claim_forward_h, _, claim_backward_h, _ = Bidirectional(LSTM(UNITS, return_sequences=True, return_state=True))(claim_outputs)\n",
        "  claim_outputs1 = Concatenate()([claim_forward_h, claim_backward_h])\n",
        "\n",
        "  evidence_outputs1, evidence_forward_h, _, evidence_backward_h, _ = Bidirectional(LSTM(UNITS, return_sequences=True, return_state=True))(evidence_outputs)\n",
        "  evidence_outputs1 = Concatenate()([evidence_forward_h, evidence_backward_h])\n",
        "  return claim_outputs1, evidence_outputs1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02UpoOhMWfkk"
      },
      "source": [
        "### RNN averaging all states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60QZFNFWksv"
      },
      "source": [
        "def avg_model():  \n",
        "  claim_outputs2 = Bidirectional(LSTM(UNITS, return_sequences=True))(claim_outputs)\n",
        "  evidence_outputs2 = Bidirectional(LSTM(UNITS, return_sequences=True))(evidence_outputs)\n",
        "\n",
        "  claim_outputs2 = GlobalAveragePooling1D()(claim_outputs2)\n",
        "  evidence_outputs2 = GlobalAveragePooling1D()(evidence_outputs2)\n",
        "  return claim_outputs2, evidence_outputs2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD6YAMxkWlDf"
      },
      "source": [
        "### Using MLP layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxihz-vubFJ"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(Linear, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zzIgH1RhTO3"
      },
      "source": [
        "class MLPBlock(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.maxpool = GlobalMaxPooling1D()\n",
        "        self.linear_1 = Linear(512)\n",
        "        self.linear_2 = Linear(256)\n",
        "        self.linear_3 = Linear(64)\n",
        "        self.dropout = Dropout(0.1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.maxpool(inputs)\n",
        "        x = self.linear_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.linear_3(x)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJnI7BK0WqbN"
      },
      "source": [
        "def mlp_model():  \n",
        "  mlp = MLPBlock()\n",
        "  claim_outputs3 = mlp(claim_outputs)\n",
        "  evidence_outputs3 = mlp(evidence_outputs)\n",
        "  return claim_outputs3, evidence_outputs3"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMRffpEIWqv5"
      },
      "source": [
        "### Using BoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkcZJb_Wtqe"
      },
      "source": [
        "import keras.layers as L\n",
        "import keras.backend as K\n",
        "\n",
        "class NonZeroMean(L.Layer):\n",
        "  def call(self, x): \n",
        "    \"\"\"Calculate non-zero mean.\"\"\"\n",
        "    # count the number of nonzero features on embedding axis\n",
        "    nonzero = K.any(K.not_equal(x, 0.0), axis=-1)\n",
        "    n = K.sum(K.cast(nonzero, 'float32'), axis=-1, keepdims=True)\n",
        "    # average on max_tokens axis\n",
        "    x_mean = K.sum(x, axis=-2) / n\n",
        "    return x_mean\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    \"\"\"Collapse summation axis.\"\"\"\n",
        "    return input_shape[:-2] + (input_shape[-1],)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPYUfWzilT5-"
      },
      "source": [
        "def bow_model():\n",
        "  claim_outputs4 = NonZeroMean()(claim_outputs)\n",
        "  evidence_outputs4 = NonZeroMean()(evidence_outputs)\n",
        "  return claim_outputs4, evidence_outputs4"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYAHp1SthFLm"
      },
      "source": [
        "## Final part of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OKk6Htb4UKH"
      },
      "source": [
        "def concat_model(claim_model, evidence_model):\n",
        "  claim = Dropout(0.2)(claim_model.output)\n",
        "  evidence = Dropout(0.2)(evidence_model.output)\n",
        "  combined = concatenate([claim, evidence], name='combined_output')\n",
        "\n",
        "  combined = Dense(128, activation='relu')(combined)\n",
        "  combined = Dense(64, activation='relu')(combined)\n",
        "  z = Dense(1, activation='sigmoid')(combined)\n",
        "  return z"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt0269pInUJM"
      },
      "source": [
        "def concat_model_w_similarity(claim_model, evidence_model):\r\n",
        "  claim = Dropout(0.2)(claim_model.output)\r\n",
        "  evidence = Dropout(0.2)(evidence_model.output)\r\n",
        "  sentence_similarity = Dot(axes=1)([claim_model.output, evidence_model.output])\r\n",
        "\r\n",
        "  combined = concatenate([claim, evidence, sentence_similarity], name='combined_output')\r\n",
        "\r\n",
        "  combined = Dense(128, activation='relu')(combined)\r\n",
        "  combined = Dense(64, activation='relu')(combined)\r\n",
        "  z = Dense(1, activation='sigmoid')(combined)\r\n",
        "  return z"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIITxbfe4diD"
      },
      "source": [
        "def sum_model(claim_model, evidence_model):\n",
        "  claim = Dropout(0.2)(claim_model.output)\n",
        "  evidence = Dropout(0.2)(evidence_model.output)\n",
        "  combined = Add()([claim, evidence])\n",
        "\n",
        "  combined = Dense(128, activation='relu')(combined)\n",
        "  combined = Dense(64, activation='relu')(combined)\n",
        "  z = Dense(1, activation='sigmoid')(combined)\n",
        "  return z"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-pLpxe04dp2"
      },
      "source": [
        "def mean_model(claim_model, evidence_model):\n",
        "  claim = Dropout(0.2)(claim_model.output)\n",
        "  evidence = Dropout(0.2)(evidence_model.output)\n",
        "  combined = Average()([claim, evidence])\n",
        "\n",
        "  combined = Dense(128, activation='relu')(combined)\n",
        "  combined = Dense(64, activation='relu')(combined)\n",
        "  combined = Dense(2, activation='relu')(combined)\n",
        "  z = Dense(1, activation='sigmoid')(combined)\n",
        "  return z"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeFR9SFsEmDz"
      },
      "source": [
        "# encode class values as integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "\n",
        "encoded_Y_train = le.transform(y_train)\n",
        "encoded_Y_val = le.transform(y_val)\n",
        "encoded_Y_test = le.transform(y_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bms19rSC5ww"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP17ZLHohssT"
      },
      "source": [
        "models = [None] * 7\r\n",
        "i = 0"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec7XwrG0ixnG",
        "outputId": "55c2e0cf-8172-40fd-c63e-89970e833ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training all 4 model types with a common merging strategy (mean)\r\n",
        "\r\n",
        "model = {0:'LAST STATE', 1:'AVG STATES', 2:'MLP', 3:'BoW'}\r\n",
        "multi = {0:'MEAN'}\r\n",
        "\r\n",
        "for x in range(4):\r\n",
        "  encoder = TFBertModel(config=configuration)\r\n",
        "  claim_outputs = encoder(claim_input)[0]\r\n",
        "  evidence_outputs = encoder(evidence_input)[0]\r\n",
        "  if x == 0:\r\n",
        "    print('LAST STATE')\r\n",
        "    claim_outputs_fin, evidence_outputs_fin = last_state_model()\r\n",
        "  elif x == 1:\r\n",
        "    print('AVG STATES')\r\n",
        "    claim_outputs_fin, evidence_outputs_fin = avg_model()\r\n",
        "  elif x == 2:\r\n",
        "    print('MLP')\r\n",
        "    claim_outputs_fin, evidence_outputs_fin = mlp_model()\r\n",
        "  elif x == 3:\r\n",
        "    print('BoW')\r\n",
        "    claim_outputs_fin, evidence_outputs_fin = bow_model()\r\n",
        "\r\n",
        "  claim_model = Model(inputs=claim_input, outputs=claim_outputs_fin)\r\n",
        "  evidence_model = Model(inputs=evidence_input, outputs=evidence_outputs_fin)\r\n",
        "\r\n",
        "  print('MEAN')\r\n",
        "  z = mean_model(claim_model, evidence_model)\r\n",
        "\r\n",
        "  models[i] = Model(inputs=[claim_model.input, evidence_model.input], outputs=z)\r\n",
        "  models[i].compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  models[i].summary()\r\n",
        "  models[i].fit([train_sentences_X_claim, train_sentences_X_evidence], encoded_Y_train, batch_size=BATCH_SIZE, epochs=5, validation_data=([val_sentences_X_claim, val_sentences_X_evidence], encoded_Y_val))\r\n",
        "  \r\n",
        "  i += 1"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f3a9586a660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f3ab10b4e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f3a9586a660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f3ab10b4e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f3aaea468c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7f3aaea468c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LAST STATE\n",
            "MEAN\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 65, 2048), ( 10493952    tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 203, 2048),  10493952    tf_bert_model[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2048)         0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2048)         0           bidirectional_1[0][1]            \n",
            "                                                                 bidirectional_1[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 2048)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 2048)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average (Average)               (None, 2048)         0           dropout_4[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          262272      average[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            130         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            3           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 36,805,189\n",
            "Trainable params: 36,805,189\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.7902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 266s 266ms/step - loss: 0.5114 - accuracy: 0.7902 - val_loss: 0.6886 - val_accuracy: 0.6903\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.4226 - accuracy: 0.8283 - val_loss: 0.5609 - val_accuracy: 0.7136\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 253s 266ms/step - loss: 0.3546 - accuracy: 0.8531 - val_loss: 0.5946 - val_accuracy: 0.7009\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 253s 266ms/step - loss: 0.3312 - accuracy: 0.8636 - val_loss: 0.5981 - val_accuracy: 0.7150\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 253s 266ms/step - loss: 0.3374 - accuracy: 0.8619 - val_loss: 0.5922 - val_accuracy: 0.7239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AVG STATES\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MEAN\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 65, 2048)     10493952    tf_bert_model_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 203, 2048)    10493952    tf_bert_model_1[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 2048)         0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 2048)         0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 2048)         0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 2048)         0           global_average_pooling1d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_1 (Average)             (None, 2048)         0           dropout_10[0][0]                 \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          262272      average_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           8256        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 2)            130         dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            3           dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 36,805,189\n",
            "Trainable params: 36,805,189\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.7278"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 257s 261ms/step - loss: 0.6547 - accuracy: 0.7278 - val_loss: 0.7502 - val_accuracy: 0.5040\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 246s 259ms/step - loss: 0.5845 - accuracy: 0.7344 - val_loss: 0.8010 - val_accuracy: 0.5040\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 247s 259ms/step - loss: 0.5795 - accuracy: 0.7338 - val_loss: 0.8139 - val_accuracy: 0.5040\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 246s 259ms/step - loss: 0.5803 - accuracy: 0.7329 - val_loss: 0.8130 - val_accuracy: 0.5040\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 246s 259ms/step - loss: 0.5793 - accuracy: 0.7340 - val_loss: 0.8130 - val_accuracy: 0.5040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLP\n",
            "MEAN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_2 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mlp_block (MLPBlock)            (None, 64)           279360      tf_bert_model_2[0][0]            \n",
            "                                                                 tf_bert_model_2[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 64)           0           mlp_block[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 64)           0           mlp_block[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_2 (Average)             (None, 64)           0           dropout_17[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          8320        average_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 64)           8256        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 2)            130         dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1)            3           dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,842,693\n",
            "Trainable params: 15,842,693\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.7647"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 46s 44ms/step - loss: 0.5290 - accuracy: 0.7647 - val_loss: 0.6542 - val_accuracy: 0.7091\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 41s 43ms/step - loss: 0.3654 - accuracy: 0.8558 - val_loss: 0.6467 - val_accuracy: 0.7232\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 41s 43ms/step - loss: 0.3008 - accuracy: 0.8796 - val_loss: 0.6368 - val_accuracy: 0.7185\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 41s 43ms/step - loss: 0.2571 - accuracy: 0.8954 - val_loss: 0.8752 - val_accuracy: 0.7228\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 41s 43ms/step - loss: 0.2218 - accuracy: 0.9117 - val_loss: 0.7418 - val_accuracy: 0.7276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BoW\n",
            "MEAN\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_3 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean (NonZeroMean)     (None, 256)          0           tf_bert_model_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_1 (NonZeroMean)   (None, 256)          0           tf_bert_model_3[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 256)          0           non_zero_mean[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 256)          0           non_zero_mean_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_3 (Average)             (None, 256)          0           dropout_23[0][0]                 \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 128)          32896       average_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 64)           8256        dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 2)            130         dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 1)            3           dense_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,587,909\n",
            "Trainable params: 15,587,909\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.4959 - accuracy: 0.7989"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 45s 43ms/step - loss: 0.4958 - accuracy: 0.7989 - val_loss: 0.6863 - val_accuracy: 0.7114\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3791 - accuracy: 0.8489 - val_loss: 0.6541 - val_accuracy: 0.7206\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3352 - accuracy: 0.8654 - val_loss: 0.6411 - val_accuracy: 0.7171\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3146 - accuracy: 0.8733 - val_loss: 0.6049 - val_accuracy: 0.7144\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2996 - accuracy: 0.8767 - val_loss: 0.6533 - val_accuracy: 0.7156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmzZF2alpC4-",
        "outputId": "7cec11fc-c318-47f5-f5cf-1deb4c7da3aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training of a single model with the other two merging strategies\r\n",
        "\r\n",
        "multi = {0:'CONCATENATE', 1:'SUM'} # MEAN STRATEGY ALREADY TESTED IN THE PREVIOUS CELL...\r\n",
        "\r\n",
        "for y in multi.keys():\r\n",
        "  claim_outputs_fin, evidence_outputs_fin = last_state_model()\r\n",
        "\r\n",
        "  claim_model = Model(inputs=claim_input, outputs=claim_outputs_fin)\r\n",
        "  evidence_model = Model(inputs=evidence_input, outputs=evidence_outputs_fin)\r\n",
        "\r\n",
        "  if y == 0:\r\n",
        "    print('CONCATENATE')\r\n",
        "    z = concat_model(claim_model, evidence_model)\r\n",
        "  elif y == 1:\r\n",
        "    print('SUM')\r\n",
        "    z = sum_model(claim_model, evidence_model)\r\n",
        "\r\n",
        "  models[i] = Model(inputs=[claim_model.input, evidence_model.input], outputs=z)\r\n",
        "  models[i].compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  models[i].summary()\r\n",
        "  models[i].fit([train_sentences_X_claim, train_sentences_X_evidence], encoded_Y_train, batch_size=BATCH_SIZE, epochs=5, validation_data=([val_sentences_X_claim, val_sentences_X_evidence], encoded_Y_val))\r\n",
        " \r\n",
        "  i += 1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CONCATENATE\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_3 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) [(None, 65, 2048), ( 10493952    tf_bert_model_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) [(None, 203, 2048),  10493952    tf_bert_model_3[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 2048)         0           bidirectional_6[0][1]            \n",
            "                                                                 bidirectional_6[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 2048)         0           bidirectional_7[0][1]            \n",
            "                                                                 bidirectional_7[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 2048)         0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 2048)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "combined_output (Concatenate)   (None, 4096)         0           dropout_27[0][0]                 \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 128)          524416      combined_output[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 64)           8256        dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 1)            65          dense_17[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 37,067,265\n",
            "Trainable params: 37,067,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.8724"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 262s 267ms/step - loss: 0.3092 - accuracy: 0.8724 - val_loss: 0.5959 - val_accuracy: 0.7170\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.2987 - accuracy: 0.8755 - val_loss: 0.6149 - val_accuracy: 0.7087\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.3141 - accuracy: 0.8716 - val_loss: 0.6826 - val_accuracy: 0.7157\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 252s 264ms/step - loss: 0.2972 - accuracy: 0.8754 - val_loss: 0.6769 - val_accuracy: 0.7034\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.2787 - accuracy: 0.8828 - val_loss: 0.6482 - val_accuracy: 0.7079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SUM\n",
            "Model: \"model_19\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_3 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_8 (Bidirectional) [(None, 65, 2048), ( 10493952    tf_bert_model_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_9 (Bidirectional) [(None, 203, 2048),  10493952    tf_bert_model_3[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2048)         0           bidirectional_8[0][1]            \n",
            "                                                                 bidirectional_8[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 2048)         0           bidirectional_9[0][1]            \n",
            "                                                                 bidirectional_9[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 2048)         0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 2048)         0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2048)         0           dropout_29[0][0]                 \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 128)          262272      add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 64)           8256        dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 1)            65          dense_20[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 36,805,121\n",
            "Trainable params: 36,805,121\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8701"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 263s 268ms/step - loss: 0.3210 - accuracy: 0.8702 - val_loss: 0.6176 - val_accuracy: 0.7076\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.2852 - accuracy: 0.8806 - val_loss: 0.6857 - val_accuracy: 0.6949\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.2922 - accuracy: 0.8775 - val_loss: 0.6613 - val_accuracy: 0.6992\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 253s 266ms/step - loss: 0.2639 - accuracy: 0.8883 - val_loss: 0.7110 - val_accuracy: 0.7117\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.2604 - accuracy: 0.8888 - val_loss: 0.7157 - val_accuracy: 0.7037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUXTTJPiDO9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fabd74-47a8-47d3-e0f3-3ddc7497fbee"
      },
      "source": [
        "# Training of a model and a strategy with the optional cosine similarity feature\n",
        "\n",
        "print('LAST HIDDEN STATES MODEL CONCATENATED WITH COSINE SIMILARITY')\n",
        "encoder = TFBertModel(config=configuration)\n",
        "claim_outputs = encoder(claim_input)[0]\n",
        "evidence_outputs = encoder(evidence_input)[0]\n",
        "claim_outputs_fin, evidence_outputs_fin = last_state_model()\n",
        "claim_model = Model(inputs=claim_input, outputs=claim_outputs_fin)\n",
        "evidence_model = Model(inputs=evidence_input, outputs=evidence_outputs_fin)\n",
        "\n",
        "z = concat_model_w_similarity(claim_model, evidence_model)\n",
        "\n",
        "models[i] = Model(inputs=[claim_model.input, evidence_model.input], outputs=z)\n",
        "models[i].compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "models[i].summary()\n",
        "models[i].fit([train_sentences_X_claim, train_sentences_X_evidence], encoded_Y_train, batch_size=BATCH_SIZE, epochs=10, validation_data=([val_sentences_X_claim, val_sentences_X_evidence], encoded_Y_val))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LAST HIDDEN STATES MODEL CONCATENATED WITH COSINE SIMILARITY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_4 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional [(None, 65, 2048), ( 10493952    tf_bert_model_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional [(None, 203, 2048),  10493952    tf_bert_model_4[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 2048)         0           bidirectional_10[0][1]           \n",
            "                                                                 bidirectional_10[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 2048)         0           bidirectional_11[0][1]           \n",
            "                                                                 bidirectional_11[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 2048)         0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 2048)         0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1)            0           concatenate_8[0][0]              \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "combined_output (Concatenate)   (None, 4097)         0           dropout_35[0][0]                 \n",
            "                                                                 dropout_36[0][0]                 \n",
            "                                                                 dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 128)          524544      combined_output[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 64)           8256        dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 1)            65          dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 37,067,393\n",
            "Trainable params: 37,067,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.8086"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 262s 266ms/step - loss: 0.4676 - accuracy: 0.8087 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 2/10\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.2948 - accuracy: 0.8756 - val_loss: 0.5418 - val_accuracy: 0.7366\n",
            "Epoch 3/10\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.2333 - accuracy: 0.9016 - val_loss: 0.5803 - val_accuracy: 0.7378\n",
            "Epoch 4/10\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.1931 - accuracy: 0.9158 - val_loss: 0.7098 - val_accuracy: 0.7311\n",
            "Epoch 5/10\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.1599 - accuracy: 0.9291 - val_loss: 0.8277 - val_accuracy: 0.7264\n",
            "Epoch 6/10\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.1351 - accuracy: 0.9390 - val_loss: 0.8805 - val_accuracy: 0.7358\n",
            "Epoch 7/10\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.1151 - accuracy: 0.9489 - val_loss: 0.8628 - val_accuracy: 0.7333\n",
            "Epoch 8/10\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.0942 - accuracy: 0.9579 - val_loss: 1.0448 - val_accuracy: 0.7263\n",
            "Epoch 9/10\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.0855 - accuracy: 0.9626 - val_loss: 1.1319 - val_accuracy: 0.7213\n",
            "Epoch 10/10\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.0698 - accuracy: 0.9703 - val_loss: 1.1783 - val_accuracy: 0.7238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f372c1bed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8_NZQwfQqVH"
      },
      "source": [
        "### The following training cell trains every possible combination of model and merging strategy, skip to test the best one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slHY-RrNmh7J",
        "outputId": "cf07bbb2-24ea-4de5-fba5-eac0d8fe9554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model1 = {0:'LAST STATE', 1:'AVG STATES', 2:'MLP', 3:'BoW'}\r\n",
        "multi = {0:'CONCATENATE', 1:'SUM', 2:'MEAN'}\r\n",
        "for x in range(4):\r\n",
        "  for y in range(3):\r\n",
        "    encoder = TFBertModel(config=configuration)\r\n",
        "    claim_outputs = encoder(claim_input)[0]\r\n",
        "    evidence_outputs = encoder(evidence_input)[0]\r\n",
        "\r\n",
        "    if x == 0:\r\n",
        "      print('LAST STATE')\r\n",
        "      claim_outputs_fin, evidence_outputs_fin = last_state_model()\r\n",
        "    elif x == 1:\r\n",
        "      print('AVG STATES')\r\n",
        "      claim_outputs_fin, evidence_outputs_fin = avg_model()\r\n",
        "    elif x == 2:\r\n",
        "      print('MLP')\r\n",
        "      claim_outputs_fin, evidence_outputs_fin = mlp_model()\r\n",
        "    elif x == 3:\r\n",
        "      print('BoW')\r\n",
        "      claim_outputs_fin, evidence_outputs_fin = bow_model()\r\n",
        "\r\n",
        "    claim_model = Model(inputs=claim_input, outputs=claim_outputs_fin)\r\n",
        "    evidence_model = Model(inputs=evidence_input, outputs=evidence_outputs_fin)\r\n",
        "\r\n",
        "    sentence_similarity = Dot(axes=1)([claim_model.output, evidence_model.output]) \r\n",
        "    if y == 0:\r\n",
        "      print('CONCATENATE')\r\n",
        "      z = concat_model(claim_model, evidence_model)\r\n",
        "    elif y == 1:\r\n",
        "      print('SUM')\r\n",
        "      z = sum_model(claim_model, evidence_model)\r\n",
        "    elif y == 2:\r\n",
        "      print('MEAN')\r\n",
        "      z = mean_model(claim_model, evidence_model)\r\n",
        "\r\n",
        "    model = Model(inputs=[claim_model.input, evidence_model.input], outputs=z)\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "    model.summary()\r\n",
        "    model.fit([train_sentences_X_claim, train_sentences_X_evidence], encoded_Y_train, batch_size=BATCH_SIZE, epochs=5, validation_data=([val_sentences_X_claim, val_sentences_X_evidence], encoded_Y_val))\r\n",
        "    model.evaluate([val_sentences_X_claim, val_sentences_X_evidence], encoded_Y_val)\r\n",
        "    y_pred = model.predict([test_sentences_X_claim, test_sentences_X_evidence])\r\n",
        "    print(classification_report(encoded_Y_test, np.round(y_pred)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LAST STATE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CONCATENATE\n",
            "Model: \"model_25\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_5 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_12 (Bidirectional [(None, 65, 2048), ( 10493952    tf_bert_model_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional [(None, 203, 2048),  10493952    tf_bert_model_5[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 2048)         0           bidirectional_12[0][1]           \n",
            "                                                                 bidirectional_12[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 2048)         0           bidirectional_13[0][1]           \n",
            "                                                                 bidirectional_13[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 2048)         0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 2048)         0           concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "combined_output (Concatenate)   (None, 4096)         0           dropout_41[0][0]                 \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 128)          524416      combined_output[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 64)           8256        dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 1)            65          dense_26[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 37,067,265\n",
            "Trainable params: 37,067,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.4697 - accuracy: 0.8023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 262s 267ms/step - loss: 0.4697 - accuracy: 0.8023 - val_loss: 0.5527 - val_accuracy: 0.7072\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.2988 - accuracy: 0.8720 - val_loss: 0.5763 - val_accuracy: 0.7294\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 253s 266ms/step - loss: 0.2433 - accuracy: 0.8964 - val_loss: 0.5551 - val_accuracy: 0.7372\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 251s 263ms/step - loss: 0.2023 - accuracy: 0.9129 - val_loss: 0.6939 - val_accuracy: 0.7245\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 253s 266ms/step - loss: 0.1748 - accuracy: 0.9227 - val_loss: 0.6871 - val_accuracy: 0.7245\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.6871 - accuracy: 0.7245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.58      0.67      3583\n",
            "           1       0.67      0.84      0.75      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.73      0.71      0.71      7189\n",
            "weighted avg       0.73      0.71      0.71      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LAST STATE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SUM\n",
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_6 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_14 (Bidirectional [(None, 65, 2048), ( 10493952    tf_bert_model_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_15 (Bidirectional [(None, 203, 2048),  10493952    tf_bert_model_6[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 2048)         0           bidirectional_14[0][1]           \n",
            "                                                                 bidirectional_14[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 2048)         0           bidirectional_15[0][1]           \n",
            "                                                                 bidirectional_15[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 2048)         0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 2048)         0           concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 2048)         0           dropout_47[0][0]                 \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 128)          262272      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 64)           8256        dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 1)            65          dense_29[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 36,805,121\n",
            "Trainable params: 36,805,121\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.8043"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 262s 266ms/step - loss: 0.4833 - accuracy: 0.8043 - val_loss: 0.5616 - val_accuracy: 0.6962\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.3040 - accuracy: 0.8694 - val_loss: 0.5465 - val_accuracy: 0.7329\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 251s 264ms/step - loss: 0.2470 - accuracy: 0.8951 - val_loss: 0.6026 - val_accuracy: 0.7256\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 252s 265ms/step - loss: 0.2084 - accuracy: 0.9092 - val_loss: 0.7741 - val_accuracy: 0.7251\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 253s 265ms/step - loss: 0.1784 - accuracy: 0.9215 - val_loss: 0.7116 - val_accuracy: 0.7316\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.7116 - accuracy: 0.7316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.55      0.66      3583\n",
            "           1       0.66      0.87      0.75      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.74      0.71      0.71      7189\n",
            "weighted avg       0.74      0.71      0.71      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LAST STATE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MEAN\n",
            "Model: \"model_31\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_7 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_16 (Bidirectional [(None, 65, 2048), ( 10493952    tf_bert_model_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_17 (Bidirectional [(None, 203, 2048),  10493952    tf_bert_model_7[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 2048)         0           bidirectional_16[0][1]           \n",
            "                                                                 bidirectional_16[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 2048)         0           bidirectional_17[0][1]           \n",
            "                                                                 bidirectional_17[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 2048)         0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 2048)         0           concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_4 (Average)             (None, 2048)         0           dropout_53[0][0]                 \n",
            "                                                                 dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 128)          262272      average_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 64)           8256        dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 2)            130         dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 1)            3           dense_33[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 36,805,189\n",
            "Trainable params: 36,805,189\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.7316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 253s 258ms/step - loss: 0.6539 - accuracy: 0.7316 - val_loss: 0.7498 - val_accuracy: 0.5040\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 244s 256ms/step - loss: 0.5856 - accuracy: 0.7332 - val_loss: 0.8024 - val_accuracy: 0.5040\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 244s 256ms/step - loss: 0.5800 - accuracy: 0.7334 - val_loss: 0.8141 - val_accuracy: 0.5040\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 243s 255ms/step - loss: 0.5802 - accuracy: 0.7331 - val_loss: 0.8137 - val_accuracy: 0.5040\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 242s 255ms/step - loss: 0.5801 - accuracy: 0.7331 - val_loss: 0.8135 - val_accuracy: 0.5040\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.8135 - accuracy: 0.5040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      3583\n",
            "           1       0.50      1.00      0.67      3606\n",
            "\n",
            "    accuracy                           0.50      7189\n",
            "   macro avg       0.25      0.50      0.33      7189\n",
            "weighted avg       0.25      0.50      0.34      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AVG STATES\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CONCATENATE\n",
            "Model: \"model_34\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_8 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_18 (Bidirectional (None, 65, 2048)     10493952    tf_bert_model_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_19 (Bidirectional (None, 203, 2048)    10493952    tf_bert_model_8[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 2048)         0           bidirectional_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_3 (Glo (None, 2048)         0           bidirectional_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 2048)         0           global_average_pooling1d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 2048)         0           global_average_pooling1d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "combined_output (Concatenate)   (None, 4096)         0           dropout_59[0][0]                 \n",
            "                                                                 dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 128)          524416      combined_output[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 64)           8256        dense_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 1)            65          dense_36[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 37,067,265\n",
            "Trainable params: 37,067,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.8036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 266s 271ms/step - loss: 0.4799 - accuracy: 0.8036 - val_loss: 0.6237 - val_accuracy: 0.6978\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 256s 269ms/step - loss: 0.3562 - accuracy: 0.8506 - val_loss: 0.5770 - val_accuracy: 0.7189\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 257s 269ms/step - loss: 0.3177 - accuracy: 0.8678 - val_loss: 0.5519 - val_accuracy: 0.7117\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 257s 270ms/step - loss: 0.2951 - accuracy: 0.8767 - val_loss: 0.6322 - val_accuracy: 0.7197\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 257s 270ms/step - loss: 0.2773 - accuracy: 0.8828 - val_loss: 0.6364 - val_accuracy: 0.7174\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.6364 - accuracy: 0.7174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.53      0.65      3583\n",
            "           1       0.66      0.89      0.76      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.74      0.71      0.70      7189\n",
            "weighted avg       0.74      0.71      0.70      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AVG STATES\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SUM\n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_9 (TFBertModel)   multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_20 (Bidirectional (None, 65, 2048)     10493952    tf_bert_model_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_21 (Bidirectional (None, 203, 2048)    10493952    tf_bert_model_9[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_4 (Glo (None, 2048)         0           bidirectional_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_5 (Glo (None, 2048)         0           bidirectional_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 2048)         0           global_average_pooling1d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 2048)         0           global_average_pooling1d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 2048)         0           dropout_65[0][0]                 \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 128)          262272      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 64)           8256        dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 1)            65          dense_39[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 36,805,121\n",
            "Trainable params: 36,805,121\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.7936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 265s 270ms/step - loss: 0.5176 - accuracy: 0.7936 - val_loss: 0.5431 - val_accuracy: 0.7080\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 256s 269ms/step - loss: 0.3406 - accuracy: 0.8562 - val_loss: 0.5343 - val_accuracy: 0.7203\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 256s 269ms/step - loss: 0.2887 - accuracy: 0.8766 - val_loss: 0.5683 - val_accuracy: 0.7209\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 256s 269ms/step - loss: 0.2585 - accuracy: 0.8892 - val_loss: 0.6128 - val_accuracy: 0.7283\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 256s 269ms/step - loss: 0.2295 - accuracy: 0.9005 - val_loss: 0.6291 - val_accuracy: 0.7171\n",
            "224/224 [==============================] - 10s 45ms/step - loss: 0.6291 - accuracy: 0.7171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.55      0.66      3583\n",
            "           1       0.66      0.87      0.75      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.73      0.71      0.70      7189\n",
            "weighted avg       0.73      0.71      0.70      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AVG STATES\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MEAN\n",
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_10 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_22 (Bidirectional (None, 65, 2048)     10493952    tf_bert_model_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_23 (Bidirectional (None, 203, 2048)    10493952    tf_bert_model_10[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 2048)         0           bidirectional_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_7 (Glo (None, 2048)         0           bidirectional_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 2048)         0           global_average_pooling1d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 2048)         0           global_average_pooling1d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_5 (Average)             (None, 2048)         0           dropout_71[0][0]                 \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 128)          262272      average_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 64)           8256        dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 2)            130         dense_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 1)            3           dense_43[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 36,805,189\n",
            "Trainable params: 36,805,189\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.7321"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r952/952 [==============================] - 257s 261ms/step - loss: 0.6524 - accuracy: 0.7321 - val_loss: 0.7504 - val_accuracy: 0.5040\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 247s 259ms/step - loss: 0.5855 - accuracy: 0.7331 - val_loss: 0.8027 - val_accuracy: 0.5040\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 247s 260ms/step - loss: 0.5789 - accuracy: 0.7345 - val_loss: 0.8139 - val_accuracy: 0.5040\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 247s 259ms/step - loss: 0.5800 - accuracy: 0.7333 - val_loss: 0.8139 - val_accuracy: 0.5040\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 246s 259ms/step - loss: 0.5796 - accuracy: 0.7337 - val_loss: 0.8130 - val_accuracy: 0.5040\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.8130 - accuracy: 0.5040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      3583\n",
            "           1       0.50      1.00      0.67      3606\n",
            "\n",
            "    accuracy                           0.50      7189\n",
            "   macro avg       0.25      0.50      0.33      7189\n",
            "weighted avg       0.25      0.50      0.34      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLP\n",
            "CONCATENATE\n",
            "Model: \"model_43\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_11 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mlp_block_1 (MLPBlock)          (None, 64)           279360      tf_bert_model_11[0][0]           \n",
            "                                                                 tf_bert_model_11[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 64)           0           mlp_block_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 64)           0           mlp_block_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "combined_output (Concatenate)   (None, 128)          0           dropout_78[0][0]                 \n",
            "                                                                 dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 128)          16512       combined_output[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 64)           8256        dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 1)            65          dense_46[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,850,817\n",
            "Trainable params: 15,850,817\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.7764"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 45s 43ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.5772 - val_accuracy: 0.7083\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3480 - accuracy: 0.8527 - val_loss: 0.5516 - val_accuracy: 0.7333\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2849 - accuracy: 0.8798 - val_loss: 0.5847 - val_accuracy: 0.7357\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2495 - accuracy: 0.8927 - val_loss: 0.6144 - val_accuracy: 0.7263\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2132 - accuracy: 0.9063 - val_loss: 0.6261 - val_accuracy: 0.7234\n",
            "224/224 [==============================] - 2s 7ms/step - loss: 0.6261 - accuracy: 0.7234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.60      0.68      3583\n",
            "           1       0.68      0.84      0.75      3606\n",
            "\n",
            "    accuracy                           0.72      7189\n",
            "   macro avg       0.74      0.72      0.72      7189\n",
            "weighted avg       0.74      0.72      0.72      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLP\n",
            "SUM\n",
            "Model: \"model_46\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_12 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mlp_block_2 (MLPBlock)          (None, 64)           279360      tf_bert_model_12[0][0]           \n",
            "                                                                 tf_bert_model_12[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 64)           0           mlp_block_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 64)           0           mlp_block_2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64)           0           dropout_85[0][0]                 \n",
            "                                                                 dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 128)          8320        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 64)           8256        dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 1)            65          dense_49[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,842,625\n",
            "Trainable params: 15,842,625\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.7707"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 44s 42ms/step - loss: 0.5234 - accuracy: 0.7708 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3276 - accuracy: 0.8608 - val_loss: 0.5632 - val_accuracy: 0.7357\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2577 - accuracy: 0.8893 - val_loss: 0.5919 - val_accuracy: 0.7232\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2143 - accuracy: 0.9060 - val_loss: 0.7145 - val_accuracy: 0.7292\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.1793 - accuracy: 0.9188 - val_loss: 0.7957 - val_accuracy: 0.7255\n",
            "224/224 [==============================] - 2s 7ms/step - loss: 0.7957 - accuracy: 0.7255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.60      0.68      3583\n",
            "           1       0.67      0.83      0.74      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.73      0.71      0.71      7189\n",
            "weighted avg       0.73      0.71      0.71      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLP\n",
            "MEAN\n",
            "Model: \"model_49\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_13 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mlp_block_3 (MLPBlock)          (None, 64)           279360      tf_bert_model_13[0][0]           \n",
            "                                                                 tf_bert_model_13[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 64)           0           mlp_block_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 64)           0           mlp_block_3[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_6 (Average)             (None, 64)           0           dropout_92[0][0]                 \n",
            "                                                                 dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 128)          8320        average_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 64)           8256        dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 2)            130         dense_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 1)            3           dense_53[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,842,693\n",
            "Trainable params: 15,842,693\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.5825 - accuracy: 0.7313"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 47s 43ms/step - loss: 0.5824 - accuracy: 0.7314 - val_loss: 0.8138 - val_accuracy: 0.5040\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.4944 - accuracy: 0.7969 - val_loss: 0.7274 - val_accuracy: 0.6655\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.4319 - accuracy: 0.8309 - val_loss: 0.8781 - val_accuracy: 0.6805\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.4170 - accuracy: 0.8311 - val_loss: 0.9281 - val_accuracy: 0.6547\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3864 - accuracy: 0.8375 - val_loss: 0.8211 - val_accuracy: 0.6839\n",
            "224/224 [==============================] - 2s 7ms/step - loss: 0.8211 - accuracy: 0.6839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.49      0.60      3583\n",
            "           1       0.63      0.86      0.73      3606\n",
            "\n",
            "    accuracy                           0.68      7189\n",
            "   macro avg       0.71      0.68      0.67      7189\n",
            "weighted avg       0.71      0.68      0.67      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BoW\n",
            "CONCATENATE\n",
            "Model: \"model_52\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_14 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_2 (NonZeroMean)   (None, 256)          0           tf_bert_model_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_3 (NonZeroMean)   (None, 256)          0           tf_bert_model_14[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 256)          0           non_zero_mean_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 256)          0           non_zero_mean_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "combined_output (Concatenate)   (None, 512)          0           dropout_98[0][0]                 \n",
            "                                                                 dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 128)          65664       combined_output[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 64)           8256        dense_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 1)            65          dense_56[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,620,609\n",
            "Trainable params: 15,620,609\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.8085"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 44s 42ms/step - loss: 0.4620 - accuracy: 0.8085 - val_loss: 0.6311 - val_accuracy: 0.7066\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 39s 41ms/step - loss: 0.3496 - accuracy: 0.8514 - val_loss: 0.5693 - val_accuracy: 0.7143\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 39s 41ms/step - loss: 0.3109 - accuracy: 0.8678 - val_loss: 0.5976 - val_accuracy: 0.7218\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 39s 41ms/step - loss: 0.2890 - accuracy: 0.8785 - val_loss: 0.6237 - val_accuracy: 0.7210\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 39s 41ms/step - loss: 0.2667 - accuracy: 0.8859 - val_loss: 0.6222 - val_accuracy: 0.7186\n",
            "224/224 [==============================] - 2s 7ms/step - loss: 0.6222 - accuracy: 0.7186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.54      0.64      3583\n",
            "           1       0.65      0.87      0.75      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.73      0.71      0.70      7189\n",
            "weighted avg       0.73      0.71      0.70      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BoW\n",
            "SUM\n",
            "Model: \"model_55\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_15 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_4 (NonZeroMean)   (None, 256)          0           tf_bert_model_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_5 (NonZeroMean)   (None, 256)          0           tf_bert_model_15[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 256)          0           non_zero_mean_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 256)          0           non_zero_mean_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 256)          0           dropout_104[0][0]                \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 128)          32896       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 64)           8256        dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 1)            65          dense_59[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,587,841\n",
            "Trainable params: 15,587,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.8000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 44s 42ms/step - loss: 0.4806 - accuracy: 0.8001 - val_loss: 0.6086 - val_accuracy: 0.7003\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3532 - accuracy: 0.8480 - val_loss: 0.5950 - val_accuracy: 0.7066\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3241 - accuracy: 0.8610 - val_loss: 0.6443 - val_accuracy: 0.7256\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 39s 41ms/step - loss: 0.3017 - accuracy: 0.8718 - val_loss: 0.7023 - val_accuracy: 0.7020\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 39s 41ms/step - loss: 0.2913 - accuracy: 0.8755 - val_loss: 0.6407 - val_accuracy: 0.7175\n",
            "224/224 [==============================] - 2s 7ms/step - loss: 0.6407 - accuracy: 0.7175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.58      0.66      3583\n",
            "           1       0.66      0.81      0.73      3606\n",
            "\n",
            "    accuracy                           0.70      7189\n",
            "   macro avg       0.71      0.70      0.69      7189\n",
            "weighted avg       0.71      0.70      0.69      7189\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BoW\n",
            "MEAN\n",
            "Model: \"model_58\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "claim_input (InputLayer)        [(None, 65)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "evidence_input (InputLayer)     [(None, 203)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_16 (TFBertModel)  multiple             15546624    claim_input[0][0]                \n",
            "                                                                 evidence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_6 (NonZeroMean)   (None, 256)          0           tf_bert_model_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "non_zero_mean_7 (NonZeroMean)   (None, 256)          0           tf_bert_model_16[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 256)          0           non_zero_mean_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 256)          0           non_zero_mean_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_7 (Average)             (None, 256)          0           dropout_110[0][0]                \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 128)          32896       average_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 64)           8256        dense_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_63 (Dense)                (None, 2)            130         dense_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_64 (Dense)                (None, 1)            3           dense_63[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 15,587,909\n",
            "Trainable params: 15,587,909\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "951/952 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.8059"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "952/952 [==============================] - 44s 42ms/step - loss: 0.4725 - accuracy: 0.8059 - val_loss: 0.5725 - val_accuracy: 0.6980\n",
            "Epoch 2/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3747 - accuracy: 0.8419 - val_loss: 0.6022 - val_accuracy: 0.7143\n",
            "Epoch 3/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3381 - accuracy: 0.8580 - val_loss: 0.7343 - val_accuracy: 0.6973\n",
            "Epoch 4/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.3135 - accuracy: 0.8666 - val_loss: 0.6597 - val_accuracy: 0.7309\n",
            "Epoch 5/5\n",
            "952/952 [==============================] - 40s 42ms/step - loss: 0.2988 - accuracy: 0.8738 - val_loss: 0.6213 - val_accuracy: 0.7217\n",
            "224/224 [==============================] - 2s 7ms/step - loss: 0.6213 - accuracy: 0.7217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.53      0.64      3583\n",
            "           1       0.66      0.89      0.76      3606\n",
            "\n",
            "    accuracy                           0.71      7189\n",
            "   macro avg       0.74      0.71      0.70      7189\n",
            "weighted avg       0.74      0.71      0.70      7189\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyYUZabrC8PR"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-7rULzI42uY"
      },
      "source": [
        "### Majority voting evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m1emZmzmvti"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "def list_duplicates(seq):\r\n",
        "    tally = defaultdict(list)\r\n",
        "    for i,item in enumerate(seq):\r\n",
        "        tally[item].append(i)\r\n",
        "    return (locs for _, locs in tally.items() if len(locs)>1)\r\n",
        "\r\n",
        "def majority_voting_evaluation(split, encoded_labels, predictions):\r\n",
        "    ids = split['ID'].values\r\n",
        "    duplicates_indices = [dup for dup in sorted(list_duplicates(ids))]\r\n",
        "\r\n",
        "    # list of indexes of duplicates to delete\r\n",
        "    flattened = [val for sublist in duplicates_indices for val in sublist[1:]]\r\n",
        "\r\n",
        "    for dup in duplicates_indices:\r\n",
        "        curr_labels = []\r\n",
        "        for d in dup:\r\n",
        "            curr_labels.append(predictions[d])\r\n",
        "            # Majority voting algorithm\r\n",
        "            candidate = 0\r\n",
        "            count = 0\r\n",
        "            for value in curr_labels:\r\n",
        "              if count == 0:\r\n",
        "                candidate = value\r\n",
        "              if candidate == value:\r\n",
        "                count += 1\r\n",
        "              else:\r\n",
        "                count -= 1\r\n",
        "            voted_label = candidate\r\n",
        "            predictions[dup[0]] = voted_label\r\n",
        "\r\n",
        "    real_labels = np.delete(encoded_labels, flattened) # delete labels of duplicates\r\n",
        "    predictions = np.delete(predictions, flattened)\r\n",
        "\r\n",
        "    return real_labels, predictions"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO-xz0IXqDbT"
      },
      "source": [
        "## Evaluation of all models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB7On1z9pwmi"
      },
      "source": [
        "model_titles = ['LAST HIDDEN STATE WITH MEAN', 'AVERAGE HIDDEN STATES WITH MEAN', 'MLP LAYER WITH MEAN', 'BAG OF WORDS WITH MEAN', 'LAST HIDDEN STATE WITH CONCATENATION', 'LAST HIDDEN STATE WITH SUM', 'LAST HIDDEN STATE WITH CONCATENATION AND COSINE SIMILARITY']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Az5jHVqf51U",
        "outputId": "81d45c5f-3121-4542-820b-25b998cf1746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for k, model in enumerate(models):\r\n",
        "  print('-' * 50)\r\n",
        "  print(model_titles[k])\r\n",
        "  print('-' * 50)\r\n",
        "  print()\r\n",
        "\r\n",
        "  # STANDARD EVALUATION\r\n",
        "  print('STANDARD EVALUATION')\r\n",
        "  y_pred = model.predict([val_sentences_X_claim, val_sentences_X_evidence])\r\n",
        "  print(classification_report(encoded_Y_val, np.round(y_pred)))\r\n",
        "\r\n",
        "  # MAJORITY VOTING EVALUATION\r\n",
        "  print('MAJORITY VOTING EVALUATION')\r\n",
        "  y_true, y_predicted = majority_voting_evaluation(val, encoded_Y_val, y_pred)\r\n",
        "  print(classification_report(y_true, np.round(y_predicted)))\r\n",
        "\r\n",
        "  print()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "LAST HIDDEN STATE WITH MEAN\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.55      0.66      3554\n",
            "           1       0.67      0.89      0.77      3611\n",
            "\n",
            "    accuracy                           0.72      7165\n",
            "   macro avg       0.75      0.72      0.72      7165\n",
            "weighted avg       0.75      0.72      0.72      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.55      0.67      3308\n",
            "           1       0.67      0.89      0.76      3304\n",
            "\n",
            "    accuracy                           0.72      6612\n",
            "   macro avg       0.75      0.72      0.71      6612\n",
            "weighted avg       0.75      0.72      0.71      6612\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "AVERAGE HIDDEN STATES WITH MEAN\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      3554\n",
            "           1       0.50      1.00      0.67      3611\n",
            "\n",
            "    accuracy                           0.50      7165\n",
            "   macro avg       0.25      0.50      0.34      7165\n",
            "weighted avg       0.25      0.50      0.34      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      3308\n",
            "           1       0.50      1.00      0.67      3304\n",
            "\n",
            "    accuracy                           0.50      6612\n",
            "   macro avg       0.25      0.50      0.33      6612\n",
            "weighted avg       0.25      0.50      0.33      6612\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "MLP LAYER WITH MEAN\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.69      0.71      3554\n",
            "           1       0.71      0.77      0.74      3611\n",
            "\n",
            "    accuracy                           0.73      7165\n",
            "   macro avg       0.73      0.73      0.73      7165\n",
            "weighted avg       0.73      0.73      0.73      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.69      0.71      3308\n",
            "           1       0.71      0.77      0.74      3304\n",
            "\n",
            "    accuracy                           0.73      6612\n",
            "   macro avg       0.73      0.73      0.73      6612\n",
            "weighted avg       0.73      0.73      0.73      6612\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "BAG OF WORDS WITH MEAN\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.45      0.58      3554\n",
            "           1       0.62      0.89      0.73      3611\n",
            "\n",
            "    accuracy                           0.67      7165\n",
            "   macro avg       0.71      0.67      0.66      7165\n",
            "weighted avg       0.71      0.67      0.66      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.46      0.58      3308\n",
            "           1       0.62      0.89      0.73      3304\n",
            "\n",
            "    accuracy                           0.67      6612\n",
            "   macro avg       0.71      0.67      0.66      6612\n",
            "weighted avg       0.71      0.67      0.66      6612\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "LAST HIDDEN STATE WITH CONCATENATION\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.55      0.64      3554\n",
            "           1       0.66      0.86      0.74      3611\n",
            "\n",
            "    accuracy                           0.70      7165\n",
            "   macro avg       0.72      0.70      0.69      7165\n",
            "weighted avg       0.72      0.70      0.69      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.55      0.65      3308\n",
            "           1       0.65      0.85      0.74      3304\n",
            "\n",
            "    accuracy                           0.70      6612\n",
            "   macro avg       0.72      0.70      0.69      6612\n",
            "weighted avg       0.72      0.70      0.69      6612\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "LAST HIDDEN STATE WITH SUM\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.49      0.62      3554\n",
            "           1       0.65      0.91      0.76      3611\n",
            "\n",
            "    accuracy                           0.70      7165\n",
            "   macro avg       0.75      0.70      0.69      7165\n",
            "weighted avg       0.75      0.70      0.69      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.49      0.62      3308\n",
            "           1       0.64      0.91      0.75      3304\n",
            "\n",
            "    accuracy                           0.70      6612\n",
            "   macro avg       0.74      0.70      0.69      6612\n",
            "weighted avg       0.74      0.70      0.69      6612\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "LAST HIDDEN STATE WITH CONCATENATION AND COSINE SIMILARITY\n",
            "--------------------------------------------------\n",
            "\n",
            "STANDARD EVALUATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.61      0.69      3554\n",
            "           1       0.69      0.84      0.75      3611\n",
            "\n",
            "    accuracy                           0.72      7165\n",
            "   macro avg       0.74      0.72      0.72      7165\n",
            "weighted avg       0.73      0.72      0.72      7165\n",
            "\n",
            "MAJORITY VOTING EVALUATION\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.61      0.69      3308\n",
            "           1       0.68      0.83      0.75      3304\n",
            "\n",
            "    accuracy                           0.72      6612\n",
            "   macro avg       0.73      0.72      0.72      6612\n",
            "weighted avg       0.73      0.72      0.72      6612\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2oIidWrrzX9"
      },
      "source": [
        "# TEST of the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHaerqnr-FS"
      },
      "source": [
        "best_idx_model = 0 # da inserire in base ai risultati precedenti...\r\n",
        "model = models[best_idx_model]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gurHq5dcq_BC",
        "outputId": "50571403-cb84-487c-c0ee-79171d15f86a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# STANDARD EVALUATION\r\n",
        "y_pred = model.predict([test_sentences_X_claim, test_sentences_X_evidence])\r\n",
        "print(classification_report(encoded_Y_test, np.round(y_pred)))\r\n",
        "\r\n",
        "# MAJORITY VOTING EVALUATION\r\n",
        "y_true, y_predicted = majority_voting_evaluation(test, encoded_Y_test, y_pred)\r\n",
        "print(classification_report(y_true, np.round(y_predicted)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.54      0.64      3583\n",
            "           1       0.65      0.87      0.75      3606\n",
            "\n",
            "    accuracy                           0.70      7189\n",
            "   macro avg       0.73      0.70      0.70      7189\n",
            "weighted avg       0.73      0.70      0.70      7189\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.54      0.65      3304\n",
            "           1       0.65      0.87      0.75      3309\n",
            "\n",
            "    accuracy                           0.70      6613\n",
            "   macro avg       0.73      0.70      0.70      6613\n",
            "weighted avg       0.73      0.70      0.70      6613\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oXneFQ2C9u7"
      },
      "source": [
        "# COMMENTARY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyHDs4QCd7k7"
      },
      "source": [
        "\r\n",
        "Group members: Giacomo D'Amicantonio, Simone Marasi\r\n",
        "\r\n",
        "In this assignment we experimented with sentence embedding. We developed several models and combinations in order to find the best one in terms of accuracy and F1 score. In particular in the embedding part we opt for BERT embeddings instead of standard GloVe, because BERT uses built-in attention and provides more useful information about the context. Comparing the two techniques we notice a small improvement using BERT. Also the choice of adding the cosine similarity (Keras Dot layer) in one of the trials allowed us to reach the best model. The majority voting evaluation provides us almost the same results as the standard one, maybe since the duplicates are not so much. Evaluation results such as precision and recall are quite imbalanced if we choose a standard threshold of 0,5 in the binary classification of the sigmoid and they become more balanced raising up that value. But in order to remain coherent with the specifications we kept it fixed to 0,5. We are quite satisfied with the results obtained with the accuracy of the best model around 74% on the test set.\r\n",
        "The best model seems to be the LAST HIDDEN STATE with MEAN as merging strategy. The preprocessing on the data consist only in cleaning all the occurrences of RSB/LSB and similar. We also deleted all the multiple occurences of words in the evidence column if the word was repeated at least twice, one after the other. \r\n",
        "We noticed that there is not a big improvement in accurancy augmenting the dimensions of the layers. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IcMoOHie0kt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}