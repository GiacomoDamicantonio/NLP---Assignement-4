{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "SQUAD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1ZSZGVnSAWtRVe8weMj3kqgl9Vh_SCAaK",
      "authorship_tag": "ABX9TyM5DRHyzbAztzmdwxR9q79y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giagia96/NLP---Assignement-4/blob/master/SQUAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmNYQXUuqadj",
        "outputId": "4bbc2060-5463-4352-bd35-4db840e3e9d7"
      },
      "source": [
        "!pip install tokenizers\r\n",
        "!pip install transformers"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.9.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tYZkp_k7j6E"
      },
      "source": [
        "from keras.layers import Input, TimeDistributed, LSTM, Bidirectional, Dense, Activation, Multiply, Add, Lambda\r\n",
        "import pandas as pd\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "from keras.layers import *\r\n",
        "import os\r\n",
        "import re\r\n",
        "import json\r\n",
        "import string\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tokenizers import BertWordPieceTokenizer\r\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\r\n",
        "import string "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dSsHrM9repF"
      },
      "source": [
        "with open('/content/drive/MyDrive/training_set.json') as f:\r\n",
        "    raw_train_data = json.load(f)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGz8gVjWkSOS",
        "outputId": "2795800d-9319-4456-e815-3d5bea8c985a"
      },
      "source": [
        "word2idx = {}\r\n",
        "idx2word = {}\r\n",
        "max_len_question = 0\r\n",
        "max_len_context = 0\r\n",
        "max_len_answer = 0\r\n",
        "idx = 1\r\n",
        "\r\n",
        "for item in raw_train_data[\"data\"]:\r\n",
        "  for para in item[\"paragraphs\"]:\r\n",
        "    context = para[\"context\"]\r\n",
        "    for qa in para[\"qas\"]:\r\n",
        "      question = qa[\"question\"]\r\n",
        "      answer = qa[\"answers\"][0][\"text\"]\r\n",
        "      text = [context, question, answer]\r\n",
        "      for txt in text:\r\n",
        "        for x in txt.split():\r\n",
        "          if '–' in x or '-' in x:\r\n",
        "            x = x.replace('–', ' ').replace('-', ' ').split()\r\n",
        "            for i in x:\r\n",
        "              i = re.sub(r'[^A-Za-z0-9]+', '', i)\r\n",
        "              if i not in word2idx.keys():\r\n",
        "                word2idx[i] = idx\r\n",
        "                idx2word[idx] = i\r\n",
        "                idx += 1\r\n",
        "          else:\r\n",
        "            x = re.sub(r'[^A-Za-z0-9]+', '', x)\r\n",
        "            if x not in word2idx.keys():\r\n",
        "              word2idx[str(x)] = idx\r\n",
        "              idx2word[idx] = x\r\n",
        "              idx += 1\r\n",
        "print(len(word2idx))\r\n",
        "print(idx)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102666\n",
            "102667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSAaKDc6NwpU",
        "outputId": "e35f28e6-dc8a-4752-df6e-272f67a820be"
      },
      "source": [
        "def tokenize(text):\r\n",
        "  sentence = []\r\n",
        "  for y in text.split():\r\n",
        "    if '–' in y or '-' in y:\r\n",
        "      y = y.replace('–', ' ').replace('-', ' ').split()\r\n",
        "      for i in y:\r\n",
        "        i = re.sub(r'[^A-Za-z0-9]+', '', i)\r\n",
        "        sentence.append(word2idx[i])\r\n",
        "    else:\r\n",
        "      y = re.sub(r'[^A-Za-z0-9]+', '', y)\r\n",
        "      sentence.append(word2idx[y])\r\n",
        "  return sentence\r\n",
        "  \r\n",
        "tokenized_context = []\r\n",
        "tokenized_question = []\r\n",
        "tokenized_answer = []\r\n",
        "unt_context = []\r\n",
        "unt_answer = []\r\n",
        "unt_question = []\r\n",
        "for item in raw_train_data[\"data\"]:\r\n",
        "  for para in item[\"paragraphs\"]:\r\n",
        "    context = para[\"context\"]\r\n",
        "    for qa in para[\"qas\"]:\r\n",
        "      question = qa[\"question\"]\r\n",
        "      answers = qa[\"answers\"]\r\n",
        "      for answer in answers:\r\n",
        "        answer1 = answer['text']\r\n",
        "        unt_context.append(context)\r\n",
        "        unt_answer.append(answer1)\r\n",
        "        unt_question.append(question)\r\n",
        "        tokenized_context.append(tokenize(context))\r\n",
        "        tokenized_answer.append(tokenize(answer1))\r\n",
        "        tokenized_question.append(tokenize(question))\r\n",
        "print(len(tokenized_context))\r\n",
        "print(len(tokenized_answer))\r\n",
        "print(len(tokenized_question))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87599\n",
            "87599\n",
            "87599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAHCcP1m-TzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b498495-bb41-4cde-ea48-c36df9382b10"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "attention_mask = []\r\n",
        "input_ids = []\r\n",
        "token_type_ids = []\r\n",
        "start_tokens = []\r\n",
        "end_tokens = []\r\n",
        "max_len = 0\r\n",
        "for x in range(len(tokenized_context)):  \r\n",
        "  input_id = tokenized_context[x] + tokenized_question[x]\r\n",
        "  toks = [(i, i+len(tokenized_answer[x])) for i in range(len(tokenized_context[x])) if tokenized_context[x][i:i+len(tokenized_answer[x])] == tokenized_answer[x]]\r\n",
        "  if len(toks) != 0:\r\n",
        "    start_token = toks[0][0]\r\n",
        "    end_token = toks[0][1]\r\n",
        "    start_tokens.append(start_token)\r\n",
        "    end_tokens.append(end_token)\r\n",
        "    attention = [1] * len(input_id)\r\n",
        "    padding_length = max_len - len(input_id)\r\n",
        "    token_ids = [0] * len(tokenized_context[x]) + [1] * len(\r\n",
        "              tokenized_question[x][0:]\r\n",
        "          )\r\n",
        "    if len(input_id) > max_len:\r\n",
        "      max_len = len(input_id)\r\n",
        "    input_ids.append(input_id)\r\n",
        "    attention_mask.append(attention)\r\n",
        "    token_type_ids.append(token_ids)\r\n",
        "\r\n",
        "input_ids_train = pad_sequences(input_ids[101:], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "attention_mask_train = pad_sequences(attention_mask[101:], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "token_type_ids_train = pad_sequences(token_type_ids[101:], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "\r\n",
        "input_ids_test = pad_sequences(input_ids[51:100], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "attention_mask_test = pad_sequences(attention_mask[51:100], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "token_type_ids_test = pad_sequences(token_type_ids[51:100], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "\r\n",
        "input_ids_val = pad_sequences(input_ids[:50], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "attention_mask_val = pad_sequences(attention_mask[:50], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "token_type_ids_val = pad_sequences(token_type_ids[:50], maxlen= max_len, padding='post', truncating = 'post')\r\n",
        "\r\n",
        "start_tokens_train = start_tokens[101:]\r\n",
        "end_tokens_train = end_tokens[101:]\r\n",
        "\r\n",
        "start_tokens_test = start_tokens[51:100]\r\n",
        "end_tokens_test = end_tokens[51:100]\r\n",
        "\r\n",
        "start_tokens_val = start_tokens[:50]\r\n",
        "end_tokens_val = end_tokens[:50]\r\n",
        "print(len(start_tokens_train))\r\n",
        "\r\n",
        "x_train = [\r\n",
        "     input_ids_train,\r\n",
        "     token_type_ids_train,\r\n",
        "     attention_mask_train\r\n",
        "]\r\n",
        "y_train = [\r\n",
        "     np.array(start_tokens_train),\r\n",
        "     np.array(end_tokens_train)\r\n",
        "]\r\n",
        "\r\n",
        "x_test = [\r\n",
        "     input_ids_test,\r\n",
        "     token_type_ids_test,\r\n",
        "     attention_mask_test\r\n",
        "]\r\n",
        "\r\n",
        "y_test = [\r\n",
        "     np.array(start_tokens_test),\r\n",
        "     np.array(end_tokens_test)\r\n",
        "]\r\n",
        "\r\n",
        "x_val = [\r\n",
        "     input_ids_val,\r\n",
        "     token_type_ids_val,\r\n",
        "     attention_mask_val\r\n",
        "]\r\n",
        "y_val = [\r\n",
        "     np.array(start_tokens_val),\r\n",
        "     np.array(end_tokens_val)\r\n",
        "]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQo73jRu17XY",
        "outputId": "46518ebd-d642-4552-aa1f-0024a3b0d6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "configuration = BertConfig() \r\n",
        "configuration.vocab_size = len(word2idx.keys())\r\n",
        "configuration.hidden_size = 756\r\n",
        "configuration.max_position_embeddings = 512\r\n",
        "configuration.num_attention_heads = 3\r\n",
        "configuration.num_hidden_layers = 3\r\n",
        "print(configuration)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 756,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 3,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 102666\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhvV2M-vBcQq"
      },
      "source": [
        "def create_model():   \r\n",
        "    encoder =TFBertModel(config=configuration)\r\n",
        "\r\n",
        "    ## QA Model\r\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\r\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\r\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\r\n",
        "    embedding = encoder(\r\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\r\n",
        "    )[0]\r\n",
        "\r\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\r\n",
        "    start_logits = layers.Flatten()(start_logits)\r\n",
        "\r\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\r\n",
        "    end_logits = layers.Flatten()(end_logits)\r\n",
        "\r\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\r\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\r\n",
        "\r\n",
        "    model = keras.Model(\r\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\r\n",
        "        outputs=[start_probs, end_probs],\r\n",
        "    )\r\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\r\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\r\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics=['accuracy'])\r\n",
        "    return model"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfMtOXcvshSL"
      },
      "source": [
        "def normalize_text(text):\r\n",
        "    text = text.lower()\r\n",
        "\r\n",
        "    # Remove punctuations\r\n",
        "    exclude = set(string.punctuation)\r\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\r\n",
        "\r\n",
        "    # Remove articles\r\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\r\n",
        "    text = re.sub(regex, \" \", text)\r\n",
        "\r\n",
        "    # Remove extra white space\r\n",
        "    text = \" \".join(text.split())\r\n",
        "    return text\r\n",
        "\r\n",
        "\r\n",
        "class ExactMatch(keras.callbacks.Callback):\r\n",
        "    \"\"\"\r\n",
        "    Each `SquadExample` object contains the character level offsets for each token\r\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\r\n",
        "    to the tokens between our predicted start and end tokens.\r\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\r\n",
        "    We calculate the percentage of data points where the span of text obtained\r\n",
        "    from model predictions matches one of the ground-truth answers.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, x_eval, y_eval):\r\n",
        "        self.x_eval = x_eval\r\n",
        "        self.y_eval = y_eval\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\r\n",
        "        count = 0\r\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\r\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\r\n",
        "            squad_eg = eval_examples_no_skip[idx]\r\n",
        "            offsets = squad_eg.context_token_to_char\r\n",
        "            start = np.argmax(start)\r\n",
        "            end = np.argmax(end)\r\n",
        "            if start >= len(offsets):\r\n",
        "                continue\r\n",
        "            pred_char_start = offsets[start][0]\r\n",
        "            if end < len(offsets):\r\n",
        "                pred_char_end = offsets[end][1]\r\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\r\n",
        "            else:\r\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\r\n",
        "\r\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\r\n",
        "            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\r\n",
        "            if normalized_pred_ans in normalized_true_ans:\r\n",
        "                count += 1\r\n",
        "        acc = count / len(self.y_eval[0])\r\n",
        "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Yk7KAfsck8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db3a56a-dc24-4535-8952-0d8934051c8c"
      },
      "source": [
        "use_tpu = True\r\n",
        "import tensorflow as tf\r\n",
        "if use_tpu:\r\n",
        "    # Create distribution strategy\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "\r\n",
        "    # Create model\r\n",
        "    with strategy.scope():\r\n",
        "        model = create_model()\r\n",
        "else:\r\n",
        "    model = create_model()\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.121.244.34:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.121.244.34:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.121.244.34:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.121.244.34:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 666)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           [(None, 666)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           [(None, 666)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_9 (TFBertModel)   TFBaseModelOutputWit 99400536    input_22[0][0]                   \n",
            "                                                                 input_24[0][0]                   \n",
            "                                                                 input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 666, 1)       756         tf_bert_model_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 666, 1)       756         tf_bert_model_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 666)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_15 (Flatten)            (None, 666)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 666)          0           flatten_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 666)          0           flatten_15[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 99,402,048\n",
            "Trainable params: 99,402,048\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcuOff6dsjco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "ec09e0b4-eae1-4fc9-ec5f-afa1bde57da5"
      },
      "source": [
        "model.fit(\r\n",
        "    x_train,\r\n",
        "    y_train,\r\n",
        "    epochs=30,  # For demonstration, 3 epochs are recommended\r\n",
        "    batch_size=256,\r\n",
        "    validation_data = (x_val, y_val),\r\n",
        ")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "337/337 [==============================] - ETA: 0s - loss: 9.1488 - activation_18_loss: 4.5209 - activation_19_loss: 4.6279 - activation_18_accuracy: 0.0371 - activation_19_accuracy: 0.0418"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r337/337 [==============================] - 173s 423ms/step - loss: 9.1478 - activation_18_loss: 4.5203 - activation_19_loss: 4.6274 - activation_18_accuracy: 0.0372 - activation_19_accuracy: 0.0418 - val_loss: 8.2807 - val_activation_18_loss: 3.8610 - val_activation_19_loss: 4.4198 - val_activation_18_accuracy: 0.1200 - val_activation_19_accuracy: 0.0400\n",
            "Epoch 2/100\n",
            "337/337 [==============================] - 116s 345ms/step - loss: 8.2098 - activation_18_loss: 3.9060 - activation_19_loss: 4.3038 - activation_18_accuracy: 0.0764 - activation_19_accuracy: 0.0568 - val_loss: 7.9257 - val_activation_18_loss: 3.6391 - val_activation_19_loss: 4.2866 - val_activation_18_accuracy: 0.1800 - val_activation_19_accuracy: 0.0600\n",
            "Epoch 3/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 7.8304 - activation_18_loss: 3.6501 - activation_19_loss: 4.1802 - activation_18_accuracy: 0.1077 - activation_19_accuracy: 0.0652 - val_loss: 7.6802 - val_activation_18_loss: 3.4356 - val_activation_19_loss: 4.2445 - val_activation_18_accuracy: 0.2200 - val_activation_19_accuracy: 0.0800\n",
            "Epoch 4/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 7.4928 - activation_18_loss: 3.4301 - activation_19_loss: 4.0627 - activation_18_accuracy: 0.1525 - activation_19_accuracy: 0.0799 - val_loss: 7.5833 - val_activation_18_loss: 3.3615 - val_activation_19_loss: 4.2218 - val_activation_18_accuracy: 0.2400 - val_activation_19_accuracy: 0.0600\n",
            "Epoch 5/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 7.2034 - activation_18_loss: 3.2653 - activation_19_loss: 3.9381 - activation_18_accuracy: 0.1808 - activation_19_accuracy: 0.0955 - val_loss: 7.5857 - val_activation_18_loss: 3.4229 - val_activation_19_loss: 4.1628 - val_activation_18_accuracy: 0.1800 - val_activation_19_accuracy: 0.0800\n",
            "Epoch 6/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 6.8915 - activation_18_loss: 3.1053 - activation_19_loss: 3.7862 - activation_18_accuracy: 0.2095 - activation_19_accuracy: 0.1169 - val_loss: 7.6053 - val_activation_18_loss: 3.4705 - val_activation_19_loss: 4.1348 - val_activation_18_accuracy: 0.2600 - val_activation_19_accuracy: 0.1400\n",
            "Epoch 7/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 6.4820 - activation_18_loss: 2.9140 - activation_19_loss: 3.5681 - activation_18_accuracy: 0.2430 - activation_19_accuracy: 0.1485 - val_loss: 7.6501 - val_activation_18_loss: 3.4605 - val_activation_19_loss: 4.1897 - val_activation_18_accuracy: 0.1400 - val_activation_19_accuracy: 0.0800\n",
            "Epoch 8/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 5.8959 - activation_18_loss: 2.6588 - activation_19_loss: 3.2371 - activation_18_accuracy: 0.2974 - activation_19_accuracy: 0.2063 - val_loss: 7.6464 - val_activation_18_loss: 3.6200 - val_activation_19_loss: 4.0264 - val_activation_18_accuracy: 0.2800 - val_activation_19_accuracy: 0.1800\n",
            "Epoch 9/100\n",
            "337/337 [==============================] - 116s 344ms/step - loss: 5.2181 - activation_18_loss: 2.3703 - activation_19_loss: 2.8478 - activation_18_accuracy: 0.3602 - activation_19_accuracy: 0.2732 - val_loss: 8.2206 - val_activation_18_loss: 3.9350 - val_activation_19_loss: 4.2857 - val_activation_18_accuracy: 0.2200 - val_activation_19_accuracy: 0.1800\n",
            "Epoch 10/100\n",
            "128/337 [==========>...................] - ETA: 1:11 - loss: 4.3744 - activation_18_loss: 1.9835 - activation_19_loss: 2.3909 - activation_18_accuracy: 0.4554 - activation_19_accuracy: 0.3675"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-58e885b63dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# For demonstration, 3 epochs are recommended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvtruxev8Cey"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}